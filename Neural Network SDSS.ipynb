{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy\n",
    "import pandas\n",
    "import itertools\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.layers import Dense, Input, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot, rcParams\n",
    "from jupyter_progressbar import ProgressBar\n",
    "\n",
    "# rcParams['font.family'] = 'Lucinda Console'\n",
    "rcParams['font.size'] = '24'\n",
    "rcParams['figure.figsize'] = (20, 10)\n",
    "rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hopefully stable way to load data cross-pandas versions\n",
    "with open('data.p3', 'rb') as f:\n",
    "        columns, matrix = pickle.load(f)\n",
    "\n",
    "data = pandas.DataFrame(matrix, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How the data was stored initially\n",
    "#\n",
    "# with open('data.p3', 'wb') as f:\n",
    "#     pickle.dump(\n",
    "#         (data.columns, data.as_matrix()), f\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['GALAXY', 'QSO', 'STAR']\n",
    "class_to_label = {l: i for i, l in enumerate(labels)}\n",
    "\n",
    "class_labels = numpy.array([class_to_label[c] for c in data['class']])\n",
    "\n",
    "# Input columns, they should not include the actual class of course.\n",
    "columns = list(set(data.columns) - {'class'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero mean, standard deviation 1. It's OK to normalize on the test data as well, I guess,\n",
    "# since there are many samples.\n",
    "for column in columns:\n",
    "    data[column] = data[column] - data[column].mean()\n",
    "    data[column] = data[column] / data[column].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_balanced_indices(y, f=0.2):\n",
    "    \"\"\"Based on labels in y, returns at iterator that each time\n",
    "    stochastically extracts f fraction of each class w.r.t. the\n",
    "    lowest class count. Returns a boolean 1D array.\"\"\"\n",
    "    counts = Counter(y)\n",
    "    n = round(f * min(counts.values()))\n",
    "    \n",
    "    counts = Counter(y)\n",
    "    enum = min(counts.values())\n",
    "\n",
    "    denom = numpy.array([counts[i] for i in y])\n",
    "    frac = f * enum / denom\n",
    "    \n",
    "    def it():\n",
    "        nonlocal frac, y\n",
    "        while True:\n",
    "            yield numpy.random.rand(len(y)) < frac\n",
    "    return it()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=pyplot.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, numpy.newaxis]\n",
    "        print(\"Showing normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Showing confusion matrix, without normalization')\n",
    "    #print(cm)\n",
    "    pyplot.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     pyplot.title(title)\n",
    "#     pyplot.colorbar()\n",
    "    tick_marks = numpy.arange(len(classes))\n",
    "    pyplot.xticks(tick_marks, classes, rotation=90)\n",
    "    pyplot.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        pyplot.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    pyplot.ylabel('True label')\n",
    "    pyplot.xlabel('Predicted label')\n",
    "    pyplot.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = next(extract_balanced_indices(data['class'], f=0.2))\n",
    "train, test = data[~test_indices], data[test_indices]\n",
    "\n",
    "X_train, X_test = train[columns].as_matrix(), test[columns].as_matrix()\n",
    "y_train = numpy.array(list(map(class_to_label.get, train['class'])))\n",
    "y_test = numpy.array(list(map(class_to_label.get, test['class'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/herbert/.virtualenvs/astron/lib/python3.5/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=[<tf.Tenso...)`\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Create a 6-layer Neural network, 14 input features are densly connected to first a\n",
    "# 32 node relu-layer, then 48 node, 32, 16, and 8 node relu layer, finally the output\n",
    "# i a 3 node softmax-layer to predict for the three classes.\n",
    "\n",
    "input = last = Input(shape = X_train.shape[1:])\n",
    "for i in [32, 48, 32, 16, 8]:\n",
    "    last = Dense(i, activation='relu')(last)\n",
    "#     last = BatchNormalization()(last)\n",
    "last = Dense(3, activation='softmax')(last)\n",
    "# last = BatchNormalization()(last)\n",
    "\n",
    "model = Model(inputs=[input], output=last)\n",
    "\n",
    "# A new network, so tany previous learning curves can be deleted\n",
    "if 'history' in globals():\n",
    "    del history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51132992d4404035af896f1ff4ff30dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='<b>0</b>s passed', placeholder='0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 779429 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779429/779429 [==============================] - 4s 5us/step - loss: 0.8824 - acc: 0.6199 - val_loss: 0.6191 - val_acc: 0.7847\n",
      "Train on 779202 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779202/779202 [==============================] - 2s 2us/step - loss: 0.4385 - acc: 0.8447 - val_loss: 0.3178 - val_acc: 0.9007\n",
      "Train on 778758 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778758/778758 [==============================] - 2s 2us/step - loss: 0.2837 - acc: 0.9132 - val_loss: 0.2610 - val_acc: 0.9183\n",
      "Train on 779197 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779197/779197 [==============================] - 2s 2us/step - loss: 0.2521 - acc: 0.9212 - val_loss: 0.2453 - val_acc: 0.9219\n",
      "Train on 779263 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779263/779263 [==============================] - 2s 2us/step - loss: 0.2359 - acc: 0.9261 - val_loss: 0.2268 - val_acc: 0.9292\n",
      "Train on 778792 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778792/778792 [==============================] - 2s 2us/step - loss: 0.2232 - acc: 0.9302 - val_loss: 0.2170 - val_acc: 0.9341\n",
      "Train on 779497 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779497/779497 [==============================] - 2s 2us/step - loss: 0.2130 - acc: 0.9339 - val_loss: 0.2068 - val_acc: 0.9365\n",
      "Train on 779572 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779572/779572 [==============================] - 2s 2us/step - loss: 0.2054 - acc: 0.9365 - val_loss: 0.2001 - val_acc: 0.9387\n",
      "Train on 778711 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778711/778711 [==============================] - 2s 2us/step - loss: 0.1986 - acc: 0.9386 - val_loss: 0.1986 - val_acc: 0.9388\n",
      "Train on 779254 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779254/779254 [==============================] - 2s 2us/step - loss: 0.1944 - acc: 0.9400 - val_loss: 0.1887 - val_acc: 0.9421\n",
      "Train on 778796 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778796/778796 [==============================] - 2s 2us/step - loss: 0.1903 - acc: 0.9415 - val_loss: 0.1865 - val_acc: 0.9429\n",
      "Train on 779789 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779789/779789 [==============================] - 2s 2us/step - loss: 0.1891 - acc: 0.9419 - val_loss: 0.1867 - val_acc: 0.9421\n",
      "Train on 778516 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778516/778516 [==============================] - 2s 2us/step - loss: 0.1852 - acc: 0.9430 - val_loss: 0.1857 - val_acc: 0.9429\n",
      "Train on 778525 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778525/778525 [==============================] - 2s 3us/step - loss: 0.1838 - acc: 0.9435 - val_loss: 0.1831 - val_acc: 0.9435\n",
      "Train on 779200 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779200/779200 [==============================] - 2s 2us/step - loss: 0.1814 - acc: 0.9441 - val_loss: 0.1787 - val_acc: 0.9453\n",
      "Train on 778377 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778377/778377 [==============================] - 2s 2us/step - loss: 0.1794 - acc: 0.9447 - val_loss: 0.1825 - val_acc: 0.9441\n",
      "Train on 779232 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779232/779232 [==============================] - 2s 2us/step - loss: 0.1782 - acc: 0.9449 - val_loss: 0.1755 - val_acc: 0.9459\n",
      "Train on 779398 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779398/779398 [==============================] - 2s 3us/step - loss: 0.1761 - acc: 0.9457 - val_loss: 0.1728 - val_acc: 0.9465\n",
      "Train on 778713 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778713/778713 [==============================] - 2s 3us/step - loss: 0.1753 - acc: 0.9459 - val_loss: 0.1746 - val_acc: 0.9462\n",
      "Train on 779002 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779002/779002 [==============================] - 2s 2us/step - loss: 0.1742 - acc: 0.9464 - val_loss: 0.1729 - val_acc: 0.9473\n",
      "Train on 779090 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779090/779090 [==============================] - 2s 2us/step - loss: 0.1724 - acc: 0.9469 - val_loss: 0.1698 - val_acc: 0.9479\n",
      "Train on 779281 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779281/779281 [==============================] - 2s 3us/step - loss: 0.1722 - acc: 0.9472 - val_loss: 0.1711 - val_acc: 0.9477\n",
      "Train on 778652 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778652/778652 [==============================] - 2s 3us/step - loss: 0.1716 - acc: 0.9473 - val_loss: 0.1696 - val_acc: 0.9479\n",
      "Train on 779376 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779376/779376 [==============================] - 2s 2us/step - loss: 0.1709 - acc: 0.9474 - val_loss: 0.1700 - val_acc: 0.9481\n",
      "Train on 779130 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779130/779130 [==============================] - 2s 2us/step - loss: 0.1694 - acc: 0.9478 - val_loss: 0.1669 - val_acc: 0.9487\n",
      "Train on 778326 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778326/778326 [==============================] - 2s 2us/step - loss: 0.1684 - acc: 0.9479 - val_loss: 0.1666 - val_acc: 0.9483\n",
      "Train on 778926 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778926/778926 [==============================] - 2s 3us/step - loss: 0.1683 - acc: 0.9480 - val_loss: 0.1651 - val_acc: 0.9490\n",
      "Train on 779930 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779930/779930 [==============================] - 2s 2us/step - loss: 0.1670 - acc: 0.9483 - val_loss: 0.1639 - val_acc: 0.9494\n",
      "Train on 779426 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779426/779426 [==============================] - 2s 2us/step - loss: 0.1658 - acc: 0.9485 - val_loss: 0.1623 - val_acc: 0.9494\n",
      "Train on 778231 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778231/778231 [==============================] - 2s 2us/step - loss: 0.1646 - acc: 0.9486 - val_loss: 0.1616 - val_acc: 0.9497\n",
      "Train on 778255 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778255/778255 [==============================] - 2s 2us/step - loss: 0.1631 - acc: 0.9491 - val_loss: 0.1932 - val_acc: 0.9402\n",
      "Train on 780199 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "780199/780199 [==============================] - 2s 3us/step - loss: 0.1671 - acc: 0.9478 - val_loss: 0.1591 - val_acc: 0.9500\n",
      "Train on 779013 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779013/779013 [==============================] - 2s 2us/step - loss: 0.1618 - acc: 0.9493 - val_loss: 0.1584 - val_acc: 0.9500\n",
      "Train on 779092 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779092/779092 [==============================] - 2s 2us/step - loss: 0.1598 - acc: 0.9498 - val_loss: 0.1584 - val_acc: 0.9501\n",
      "Train on 779568 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779568/779568 [==============================] - 2s 2us/step - loss: 0.1600 - acc: 0.9496 - val_loss: 0.1558 - val_acc: 0.9509\n",
      "Train on 778050 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778050/778050 [==============================] - 2s 2us/step - loss: 0.1609 - acc: 0.9494 - val_loss: 0.1570 - val_acc: 0.9505\n",
      "Train on 779135 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779135/779135 [==============================] - 2s 2us/step - loss: 0.1584 - acc: 0.9501 - val_loss: 0.1546 - val_acc: 0.9513\n",
      "Train on 778832 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778832/778832 [==============================] - 2s 2us/step - loss: 0.1579 - acc: 0.9503 - val_loss: 0.1542 - val_acc: 0.9513\n",
      "Train on 778970 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778970/778970 [==============================] - 2s 2us/step - loss: 0.1573 - acc: 0.9504 - val_loss: 0.1595 - val_acc: 0.9502\n",
      "Train on 778869 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778869/778869 [==============================] - 2s 2us/step - loss: 0.1574 - acc: 0.9504 - val_loss: 0.1538 - val_acc: 0.9515\n",
      "Train on 779001 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779001/779001 [==============================] - 2s 2us/step - loss: 0.1565 - acc: 0.9508 - val_loss: 0.1532 - val_acc: 0.9513\n",
      "Train on 778641 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778641/778641 [==============================] - 2s 2us/step - loss: 0.1562 - acc: 0.9507 - val_loss: 0.1529 - val_acc: 0.9515\n",
      "Train on 779023 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779023/779023 [==============================] - 2s 2us/step - loss: 0.1566 - acc: 0.9506 - val_loss: 0.1535 - val_acc: 0.9518\n",
      "Train on 779215 samples, validate on 193733 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "779215/779215 [==============================] - 2s 3us/step - loss: 0.1548 - acc: 0.9511 - val_loss: 0.1515 - val_acc: 0.9522\n",
      "Train on 778788 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778788/778788 [==============================] - 2s 2us/step - loss: 0.1552 - acc: 0.9511 - val_loss: 0.1520 - val_acc: 0.9519\n",
      "Train on 778970 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778970/778970 [==============================] - 2s 2us/step - loss: 0.1545 - acc: 0.9513 - val_loss: 0.1525 - val_acc: 0.9517\n",
      "Train on 779244 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779244/779244 [==============================] - 2s 3us/step - loss: 0.1542 - acc: 0.9513 - val_loss: 0.1506 - val_acc: 0.9524\n",
      "Train on 779329 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779329/779329 [==============================] - 2s 2us/step - loss: 0.1540 - acc: 0.9513 - val_loss: 0.1499 - val_acc: 0.9527\n",
      "Train on 777952 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777952/777952 [==============================] - 2s 2us/step - loss: 0.1528 - acc: 0.9516 - val_loss: 0.1498 - val_acc: 0.9525\n",
      "Train on 778603 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778603/778603 [==============================] - 2s 2us/step - loss: 0.1527 - acc: 0.9517 - val_loss: 0.1497 - val_acc: 0.9527\n",
      "Train on 779836 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779836/779836 [==============================] - 2s 2us/step - loss: 0.1525 - acc: 0.9519 - val_loss: 0.1501 - val_acc: 0.9523\n",
      "Train on 779625 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779625/779625 [==============================] - 2s 2us/step - loss: 0.1515 - acc: 0.9521 - val_loss: 0.1500 - val_acc: 0.9523\n",
      "Train on 779156 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779156/779156 [==============================] - 2s 2us/step - loss: 0.1513 - acc: 0.9522 - val_loss: 0.1542 - val_acc: 0.9515\n",
      "Train on 779689 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779689/779689 [==============================] - 2s 3us/step - loss: 0.1532 - acc: 0.9517 - val_loss: 0.1487 - val_acc: 0.9527\n",
      "Train on 778957 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778957/778957 [==============================] - 2s 3us/step - loss: 0.1507 - acc: 0.9523 - val_loss: 0.1493 - val_acc: 0.9524\n",
      "Train on 779129 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779129/779129 [==============================] - 2s 3us/step - loss: 0.1512 - acc: 0.9521 - val_loss: 0.1473 - val_acc: 0.9531\n",
      "Train on 778794 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778794/778794 [==============================] - 2s 3us/step - loss: 0.1503 - acc: 0.9525 - val_loss: 0.1476 - val_acc: 0.9532\n",
      "Train on 778177 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778177/778177 [==============================] - 2s 3us/step - loss: 0.1511 - acc: 0.9523 - val_loss: 0.1473 - val_acc: 0.9532\n",
      "Train on 779015 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779015/779015 [==============================] - 2s 3us/step - loss: 0.1505 - acc: 0.9525 - val_loss: 0.1464 - val_acc: 0.9534\n",
      "Train on 778766 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778766/778766 [==============================] - 2s 2us/step - loss: 0.1504 - acc: 0.9525 - val_loss: 0.1476 - val_acc: 0.9534\n",
      "Train on 778516 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778516/778516 [==============================] - 2s 3us/step - loss: 0.1493 - acc: 0.9525 - val_loss: 0.1507 - val_acc: 0.9519\n",
      "Train on 779172 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779172/779172 [==============================] - 2s 3us/step - loss: 0.1481 - acc: 0.9527 - val_loss: 0.1447 - val_acc: 0.9537\n",
      "Train on 778413 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778413/778413 [==============================] - 2s 3us/step - loss: 0.1474 - acc: 0.9532 - val_loss: 0.1511 - val_acc: 0.9520\n",
      "Train on 778857 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778857/778857 [==============================] - 2s 3us/step - loss: 0.1490 - acc: 0.9527 - val_loss: 0.1462 - val_acc: 0.9536\n",
      "Train on 778779 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778779/778779 [==============================] - 3s 4us/step - loss: 0.1479 - acc: 0.9529 - val_loss: 0.1463 - val_acc: 0.9531\n",
      "Train on 779670 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779670/779670 [==============================] - 3s 4us/step - loss: 0.1480 - acc: 0.9531 - val_loss: 0.1458 - val_acc: 0.9534\n",
      "Train on 778791 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778791/778791 [==============================] - 4s 5us/step - loss: 0.1466 - acc: 0.9534 - val_loss: 0.1454 - val_acc: 0.9535\n",
      "Train on 779469 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779469/779469 [==============================] - 3s 4us/step - loss: 0.1470 - acc: 0.9533 - val_loss: 0.1437 - val_acc: 0.9538\n",
      "Train on 779202 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779202/779202 [==============================] - 3s 4us/step - loss: 0.1472 - acc: 0.9533 - val_loss: 0.1451 - val_acc: 0.9536\n",
      "Train on 779218 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779218/779218 [==============================] - 4s 5us/step - loss: 0.1473 - acc: 0.9531 - val_loss: 0.1436 - val_acc: 0.9542\n",
      "Train on 778441 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778441/778441 [==============================] - 4s 5us/step - loss: 0.1463 - acc: 0.9535 - val_loss: 0.1467 - val_acc: 0.9530\n",
      "Train on 779494 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779494/779494 [==============================] - 3s 4us/step - loss: 0.1470 - acc: 0.9530 - val_loss: 0.1442 - val_acc: 0.9537\n",
      "Train on 778215 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778215/778215 [==============================] - 3s 4us/step - loss: 0.1459 - acc: 0.9535 - val_loss: 0.1431 - val_acc: 0.9543\n",
      "Train on 778838 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778838/778838 [==============================] - 4s 5us/step - loss: 0.1454 - acc: 0.9538 - val_loss: 0.1426 - val_acc: 0.9546\n",
      "Train on 778194 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778194/778194 [==============================] - 4s 5us/step - loss: 0.1464 - acc: 0.9533 - val_loss: 0.1451 - val_acc: 0.9537\n",
      "Train on 778954 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778954/778954 [==============================] - 4s 5us/step - loss: 0.1460 - acc: 0.9535 - val_loss: 0.1423 - val_acc: 0.9545\n",
      "Train on 778765 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778765/778765 [==============================] - 4s 5us/step - loss: 0.1455 - acc: 0.9536 - val_loss: 0.1424 - val_acc: 0.9545\n",
      "Train on 779038 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779038/779038 [==============================] - 5s 6us/step - loss: 0.1452 - acc: 0.9539 - val_loss: 0.1448 - val_acc: 0.9536\n",
      "Train on 778002 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778002/778002 [==============================] - 3s 4us/step - loss: 0.1455 - acc: 0.9534 - val_loss: 0.1416 - val_acc: 0.9550\n",
      "Train on 779037 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779037/779037 [==============================] - 4s 6us/step - loss: 0.1451 - acc: 0.9538 - val_loss: 0.1431 - val_acc: 0.9545\n",
      "Train on 778802 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778802/778802 [==============================] - 5s 6us/step - loss: 0.1452 - acc: 0.9536 - val_loss: 0.1417 - val_acc: 0.9547\n",
      "Train on 778617 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778617/778617 [==============================] - 4s 5us/step - loss: 0.1443 - acc: 0.9539 - val_loss: 0.1416 - val_acc: 0.9547\n",
      "Train on 779181 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779181/779181 [==============================] - 4s 5us/step - loss: 0.1445 - acc: 0.9539 - val_loss: 0.1421 - val_acc: 0.9548\n",
      "Train on 778799 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778799/778799 [==============================] - 4s 5us/step - loss: 0.1449 - acc: 0.9537 - val_loss: 0.1425 - val_acc: 0.9542\n",
      "Train on 779908 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779908/779908 [==============================] - 3s 4us/step - loss: 0.1440 - acc: 0.9540 - val_loss: 0.1414 - val_acc: 0.9548\n",
      "Train on 779094 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779094/779094 [==============================] - 3s 4us/step - loss: 0.1438 - acc: 0.9541 - val_loss: 0.1415 - val_acc: 0.9549\n",
      "Train on 778205 samples, validate on 193733 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778205/778205 [==============================] - 3s 4us/step - loss: 0.1438 - acc: 0.9540 - val_loss: 0.1421 - val_acc: 0.9540\n",
      "Train on 779062 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779062/779062 [==============================] - 4s 5us/step - loss: 0.1427 - acc: 0.9543 - val_loss: 0.1417 - val_acc: 0.9547\n",
      "Train on 779803 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779803/779803 [==============================] - 3s 4us/step - loss: 0.1430 - acc: 0.9544 - val_loss: 0.1409 - val_acc: 0.9548\n",
      "Train on 779286 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779286/779286 [==============================] - 4s 5us/step - loss: 0.1440 - acc: 0.9542 - val_loss: 0.1407 - val_acc: 0.9550\n",
      "Train on 778980 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778980/778980 [==============================] - 3s 4us/step - loss: 0.1435 - acc: 0.9541 - val_loss: 0.1437 - val_acc: 0.9539\n",
      "Train on 778704 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778704/778704 [==============================] - 3s 4us/step - loss: 0.1436 - acc: 0.9542 - val_loss: 0.1427 - val_acc: 0.9541\n",
      "Train on 779854 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779854/779854 [==============================] - 3s 4us/step - loss: 0.1428 - acc: 0.9544 - val_loss: 0.1434 - val_acc: 0.9540\n",
      "Train on 779167 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779167/779167 [==============================] - 3s 4us/step - loss: 0.1429 - acc: 0.9544 - val_loss: 0.1405 - val_acc: 0.9552\n",
      "Train on 779551 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779551/779551 [==============================] - 4s 5us/step - loss: 0.1424 - acc: 0.9545 - val_loss: 0.1405 - val_acc: 0.9550\n",
      "Train on 778120 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778120/778120 [==============================] - 3s 4us/step - loss: 0.1421 - acc: 0.9546 - val_loss: 0.1403 - val_acc: 0.9548\n",
      "Train on 779175 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779175/779175 [==============================] - 3s 4us/step - loss: 0.1432 - acc: 0.9543 - val_loss: 0.1402 - val_acc: 0.9553\n",
      "Train on 779340 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779340/779340 [==============================] - 3s 4us/step - loss: 0.1421 - acc: 0.9547 - val_loss: 0.1420 - val_acc: 0.9543\n",
      "Train on 778182 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778182/778182 [==============================] - 3s 4us/step - loss: 0.1423 - acc: 0.9545 - val_loss: 0.1393 - val_acc: 0.9553\n",
      "Train on 779357 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779357/779357 [==============================] - 3s 4us/step - loss: 0.1419 - acc: 0.9546 - val_loss: 0.1399 - val_acc: 0.9550\n",
      "Train on 779722 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779722/779722 [==============================] - 3s 4us/step - loss: 0.1422 - acc: 0.9544 - val_loss: 0.1403 - val_acc: 0.9547\n",
      "Train on 779666 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779666/779666 [==============================] - 3s 4us/step - loss: 0.1414 - acc: 0.9548 - val_loss: 0.1406 - val_acc: 0.9551\n",
      "Train on 778410 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778410/778410 [==============================] - 3s 4us/step - loss: 0.1423 - acc: 0.9545 - val_loss: 0.1445 - val_acc: 0.9540\n",
      "Train on 780470 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "780470/780470 [==============================] - 3s 4us/step - loss: 0.1426 - acc: 0.9545 - val_loss: 0.1401 - val_acc: 0.9550\n",
      "Train on 778627 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778627/778627 [==============================] - 3s 4us/step - loss: 0.1420 - acc: 0.9545 - val_loss: 0.1395 - val_acc: 0.9552\n",
      "Train on 778657 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778657/778657 [==============================] - 3s 4us/step - loss: 0.1406 - acc: 0.9551 - val_loss: 0.1394 - val_acc: 0.9553\n",
      "Train on 780057 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "780057/780057 [==============================] - 3s 4us/step - loss: 0.1416 - acc: 0.9546 - val_loss: 0.1381 - val_acc: 0.9557\n",
      "Train on 779390 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779390/779390 [==============================] - 3s 4us/step - loss: 0.1403 - acc: 0.9551 - val_loss: 0.1438 - val_acc: 0.9539\n",
      "Train on 778346 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778346/778346 [==============================] - 4s 5us/step - loss: 0.1413 - acc: 0.9548 - val_loss: 0.1425 - val_acc: 0.9544\n",
      "Train on 778622 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778622/778622 [==============================] - 3s 4us/step - loss: 0.1411 - acc: 0.9549 - val_loss: 0.1440 - val_acc: 0.9537\n",
      "Train on 779102 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779102/779102 [==============================] - 4s 5us/step - loss: 0.1418 - acc: 0.9545 - val_loss: 0.1394 - val_acc: 0.9550\n",
      "Train on 779354 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779354/779354 [==============================] - 4s 4us/step - loss: 0.1415 - acc: 0.9549 - val_loss: 0.1389 - val_acc: 0.9556\n",
      "Train on 779450 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779450/779450 [==============================] - 4s 4us/step - loss: 0.1410 - acc: 0.9550 - val_loss: 0.1374 - val_acc: 0.9559\n",
      "Train on 779102 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779102/779102 [==============================] - 4s 5us/step - loss: 0.1397 - acc: 0.9552 - val_loss: 0.1381 - val_acc: 0.9555\n",
      "Train on 778171 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778171/778171 [==============================] - 3s 4us/step - loss: 0.1409 - acc: 0.9549 - val_loss: 0.1381 - val_acc: 0.9558\n",
      "Train on 779300 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779300/779300 [==============================] - 3s 4us/step - loss: 0.1404 - acc: 0.9550 - val_loss: 0.1395 - val_acc: 0.9551\n",
      "Train on 779549 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779549/779549 [==============================] - 3s 4us/step - loss: 0.1394 - acc: 0.9556 - val_loss: 0.1394 - val_acc: 0.9552\n",
      "Train on 779175 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779175/779175 [==============================] - 4s 4us/step - loss: 0.1395 - acc: 0.9552 - val_loss: 0.1368 - val_acc: 0.9561\n",
      "Train on 778875 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778875/778875 [==============================] - 4s 5us/step - loss: 0.1394 - acc: 0.9552 - val_loss: 0.1422 - val_acc: 0.9540\n",
      "Train on 779472 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779472/779472 [==============================] - 4s 4us/step - loss: 0.1405 - acc: 0.9548 - val_loss: 0.1379 - val_acc: 0.9557\n",
      "Train on 778197 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778197/778197 [==============================] - 4s 5us/step - loss: 0.1393 - acc: 0.9553 - val_loss: 0.1383 - val_acc: 0.9558\n",
      "Train on 778871 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778871/778871 [==============================] - 4s 4us/step - loss: 0.1401 - acc: 0.9550 - val_loss: 0.1367 - val_acc: 0.9564\n",
      "Train on 778628 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778628/778628 [==============================] - 4s 5us/step - loss: 0.1394 - acc: 0.9555 - val_loss: 0.1383 - val_acc: 0.9557\n",
      "Train on 778256 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778256/778256 [==============================] - 4s 5us/step - loss: 0.1389 - acc: 0.9554 - val_loss: 0.1480 - val_acc: 0.9530\n",
      "Train on 779237 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779237/779237 [==============================] - 3s 4us/step - loss: 0.1425 - acc: 0.9543 - val_loss: 0.1408 - val_acc: 0.9544\n",
      "Train on 778948 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778948/778948 [==============================] - 4s 5us/step - loss: 0.1395 - acc: 0.9554 - val_loss: 0.1372 - val_acc: 0.9562\n",
      "Train on 779218 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779218/779218 [==============================] - 3s 4us/step - loss: 0.1387 - acc: 0.9555 - val_loss: 0.1371 - val_acc: 0.9559\n",
      "Train on 779678 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779678/779678 [==============================] - 4s 5us/step - loss: 0.1386 - acc: 0.9557 - val_loss: 0.1368 - val_acc: 0.9560\n",
      "Train on 779554 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779554/779554 [==============================] - 3s 4us/step - loss: 0.1392 - acc: 0.9554 - val_loss: 0.1366 - val_acc: 0.9560\n",
      "Train on 779290 samples, validate on 193733 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "779290/779290 [==============================] - 3s 4us/step - loss: 0.1391 - acc: 0.9554 - val_loss: 0.1369 - val_acc: 0.9562\n",
      "Train on 778997 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778997/778997 [==============================] - 3s 4us/step - loss: 0.1388 - acc: 0.9554 - val_loss: 0.1369 - val_acc: 0.9558\n",
      "Train on 778586 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778586/778586 [==============================] - 3s 4us/step - loss: 0.1381 - acc: 0.9557 - val_loss: 0.1373 - val_acc: 0.9559\n",
      "Train on 779184 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779184/779184 [==============================] - 3s 4us/step - loss: 0.1385 - acc: 0.9558 - val_loss: 0.1359 - val_acc: 0.9563\n",
      "Train on 779136 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779136/779136 [==============================] - 3s 4us/step - loss: 0.1379 - acc: 0.9557 - val_loss: 0.1356 - val_acc: 0.9565\n",
      "Train on 778317 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778317/778317 [==============================] - 3s 4us/step - loss: 0.1378 - acc: 0.9558 - val_loss: 0.1419 - val_acc: 0.9545\n",
      "Train on 778791 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778791/778791 [==============================] - 3s 4us/step - loss: 0.1380 - acc: 0.9558 - val_loss: 0.1374 - val_acc: 0.9557\n",
      "Train on 779156 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779156/779156 [==============================] - 3s 4us/step - loss: 0.1372 - acc: 0.9560 - val_loss: 0.1358 - val_acc: 0.9564\n",
      "Train on 779543 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779543/779543 [==============================] - 3s 4us/step - loss: 0.1369 - acc: 0.9560 - val_loss: 0.1357 - val_acc: 0.9562\n",
      "Train on 778210 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778210/778210 [==============================] - 3s 4us/step - loss: 0.1367 - acc: 0.9560 - val_loss: 0.1373 - val_acc: 0.9557\n",
      "Train on 778693 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778693/778693 [==============================] - 3s 4us/step - loss: 0.1372 - acc: 0.9559 - val_loss: 0.1357 - val_acc: 0.9565\n",
      "Train on 778926 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778926/778926 [==============================] - 3s 4us/step - loss: 0.1374 - acc: 0.9559 - val_loss: 0.1353 - val_acc: 0.9566\n",
      "Train on 778319 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778319/778319 [==============================] - 3s 4us/step - loss: 0.1381 - acc: 0.9557 - val_loss: 0.1353 - val_acc: 0.9565\n",
      "Train on 778646 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778646/778646 [==============================] - 3s 4us/step - loss: 0.1373 - acc: 0.9559 - val_loss: 0.1347 - val_acc: 0.9566\n",
      "Train on 778281 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778281/778281 [==============================] - 3s 4us/step - loss: 0.1370 - acc: 0.9562 - val_loss: 0.1492 - val_acc: 0.9520\n",
      "Train on 778270 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778270/778270 [==============================] - 3s 4us/step - loss: 0.1387 - acc: 0.9556 - val_loss: 0.1461 - val_acc: 0.9535\n",
      "Train on 777916 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777916/777916 [==============================] - 3s 4us/step - loss: 0.1379 - acc: 0.9558 - val_loss: 0.1343 - val_acc: 0.9564\n",
      "Train on 779015 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779015/779015 [==============================] - 3s 4us/step - loss: 0.1368 - acc: 0.9561 - val_loss: 0.1351 - val_acc: 0.9566\n",
      "Train on 779803 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779803/779803 [==============================] - 3s 4us/step - loss: 0.1367 - acc: 0.9559 - val_loss: 0.1372 - val_acc: 0.9557\n",
      "Train on 779248 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779248/779248 [==============================] - 3s 4us/step - loss: 0.1364 - acc: 0.9563 - val_loss: 0.1366 - val_acc: 0.9560\n",
      "Train on 778241 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778241/778241 [==============================] - 3s 4us/step - loss: 0.1366 - acc: 0.9560 - val_loss: 0.1353 - val_acc: 0.9565\n",
      "Train on 778391 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778391/778391 [==============================] - 3s 4us/step - loss: 0.1368 - acc: 0.9562 - val_loss: 0.1385 - val_acc: 0.9554\n",
      "Train on 780330 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "780330/780330 [==============================] - 3s 4us/step - loss: 0.1375 - acc: 0.9558 - val_loss: 0.1343 - val_acc: 0.9569\n",
      "Train on 779129 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779129/779129 [==============================] - 3s 4us/step - loss: 0.1364 - acc: 0.9563 - val_loss: 0.1339 - val_acc: 0.9570\n",
      "Train on 779515 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779515/779515 [==============================] - 3s 4us/step - loss: 0.1362 - acc: 0.9563 - val_loss: 0.1341 - val_acc: 0.9568\n",
      "Train on 778973 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778973/778973 [==============================] - 3s 4us/step - loss: 0.1360 - acc: 0.9563 - val_loss: 0.1340 - val_acc: 0.9568\n",
      "Train on 778387 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778387/778387 [==============================] - 3s 4us/step - loss: 0.1355 - acc: 0.9565 - val_loss: 0.1354 - val_acc: 0.9566\n",
      "Train on 779381 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779381/779381 [==============================] - 4s 5us/step - loss: 0.1357 - acc: 0.9563 - val_loss: 0.1349 - val_acc: 0.9565\n",
      "Train on 778918 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778918/778918 [==============================] - 3s 4us/step - loss: 0.1358 - acc: 0.9564 - val_loss: 0.1348 - val_acc: 0.9564\n",
      "Train on 778726 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778726/778726 [==============================] - 3s 4us/step - loss: 0.1357 - acc: 0.9562 - val_loss: 0.1347 - val_acc: 0.9566\n",
      "Train on 778823 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778823/778823 [==============================] - 3s 4us/step - loss: 0.1360 - acc: 0.9562 - val_loss: 0.1359 - val_acc: 0.9563\n",
      "Train on 778332 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778332/778332 [==============================] - 4s 5us/step - loss: 0.1356 - acc: 0.9565 - val_loss: 0.1368 - val_acc: 0.9562\n",
      "Train on 778693 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778693/778693 [==============================] - 3s 4us/step - loss: 0.1364 - acc: 0.9562 - val_loss: 0.1338 - val_acc: 0.9567\n",
      "Train on 778632 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778632/778632 [==============================] - 4s 5us/step - loss: 0.1360 - acc: 0.9562 - val_loss: 0.1349 - val_acc: 0.9564\n",
      "Train on 778599 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778599/778599 [==============================] - 4s 5us/step - loss: 0.1351 - acc: 0.9565 - val_loss: 0.1334 - val_acc: 0.9570\n",
      "Train on 778078 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778078/778078 [==============================] - 3s 4us/step - loss: 0.1348 - acc: 0.9567 - val_loss: 0.1326 - val_acc: 0.9575\n",
      "Train on 777879 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777879/777879 [==============================] - 4s 5us/step - loss: 0.1350 - acc: 0.9566 - val_loss: 0.1333 - val_acc: 0.9570\n",
      "Train on 779316 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779316/779316 [==============================] - 4s 5us/step - loss: 0.1351 - acc: 0.9564 - val_loss: 0.1333 - val_acc: 0.9572\n",
      "Train on 779344 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779344/779344 [==============================] - 3s 4us/step - loss: 0.1355 - acc: 0.9564 - val_loss: 0.1370 - val_acc: 0.9560\n",
      "Train on 778979 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778979/778979 [==============================] - 4s 5us/step - loss: 0.1353 - acc: 0.9566 - val_loss: 0.1329 - val_acc: 0.9573\n",
      "Train on 778437 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778437/778437 [==============================] - 4s 5us/step - loss: 0.1348 - acc: 0.9566 - val_loss: 0.1344 - val_acc: 0.9570\n",
      "Train on 779289 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779289/779289 [==============================] - 3s 4us/step - loss: 0.1350 - acc: 0.9567 - val_loss: 0.1332 - val_acc: 0.9573\n",
      "Train on 779315 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779315/779315 [==============================] - 4s 5us/step - loss: 0.1345 - acc: 0.9567 - val_loss: 0.1330 - val_acc: 0.9575\n",
      "Train on 778648 samples, validate on 193733 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778648/778648 [==============================] - 4s 5us/step - loss: 0.1350 - acc: 0.9567 - val_loss: 0.1337 - val_acc: 0.9568\n",
      "Train on 779681 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779681/779681 [==============================] - 3s 4us/step - loss: 0.1343 - acc: 0.9570 - val_loss: 0.1329 - val_acc: 0.9574\n",
      "Train on 779754 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779754/779754 [==============================] - 3s 4us/step - loss: 0.1340 - acc: 0.9571 - val_loss: 0.1343 - val_acc: 0.9568\n",
      "Train on 779036 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779036/779036 [==============================] - 3s 4us/step - loss: 0.1349 - acc: 0.9566 - val_loss: 0.1335 - val_acc: 0.9572\n",
      "Train on 778799 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778799/778799 [==============================] - 3s 4us/step - loss: 0.1347 - acc: 0.9568 - val_loss: 0.1338 - val_acc: 0.9570\n",
      "Train on 778771 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778771/778771 [==============================] - 3s 4us/step - loss: 0.1347 - acc: 0.9568 - val_loss: 0.1322 - val_acc: 0.9573\n",
      "Train on 778889 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778889/778889 [==============================] - 4s 5us/step - loss: 0.1340 - acc: 0.9569 - val_loss: 0.1329 - val_acc: 0.9574\n",
      "Train on 779016 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779016/779016 [==============================] - 4s 5us/step - loss: 0.1344 - acc: 0.9569 - val_loss: 0.1334 - val_acc: 0.9570\n",
      "Train on 779001 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779001/779001 [==============================] - 3s 4us/step - loss: 0.1340 - acc: 0.9571 - val_loss: 0.1332 - val_acc: 0.9573\n",
      "Train on 778820 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778820/778820 [==============================] - 3s 4us/step - loss: 0.1350 - acc: 0.9567 - val_loss: 0.1344 - val_acc: 0.9566\n",
      "Train on 778027 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778027/778027 [==============================] - 5s 6us/step - loss: 0.1342 - acc: 0.9567 - val_loss: 0.1322 - val_acc: 0.9574\n",
      "Train on 779261 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779261/779261 [==============================] - 4s 5us/step - loss: 0.1342 - acc: 0.9569 - val_loss: 0.1323 - val_acc: 0.9573\n",
      "Train on 778972 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778972/778972 [==============================] - 4s 5us/step - loss: 0.1334 - acc: 0.9570 - val_loss: 0.1320 - val_acc: 0.9577\n",
      "Train on 779226 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779226/779226 [==============================] - 4s 5us/step - loss: 0.1338 - acc: 0.9569 - val_loss: 0.1328 - val_acc: 0.9577\n",
      "Train on 777588 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777588/777588 [==============================] - 4s 5us/step - loss: 0.1342 - acc: 0.9568 - val_loss: 0.1315 - val_acc: 0.9578\n",
      "Train on 778450 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778450/778450 [==============================] - 4s 5us/step - loss: 0.1337 - acc: 0.9568 - val_loss: 0.1375 - val_acc: 0.9556\n",
      "Train on 778928 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778928/778928 [==============================] - 4s 5us/step - loss: 0.1344 - acc: 0.9568 - val_loss: 0.1322 - val_acc: 0.9576\n",
      "Train on 779475 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779475/779475 [==============================] - 4s 5us/step - loss: 0.1337 - acc: 0.9572 - val_loss: 0.1318 - val_acc: 0.9576\n",
      "Train on 779213 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779213/779213 [==============================] - 4s 5us/step - loss: 0.1345 - acc: 0.9570 - val_loss: 0.1331 - val_acc: 0.9572\n",
      "Train on 779377 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779377/779377 [==============================] - 4s 5us/step - loss: 0.1342 - acc: 0.9568 - val_loss: 0.1326 - val_acc: 0.9574\n",
      "Train on 778378 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778378/778378 [==============================] - 4s 6us/step - loss: 0.1331 - acc: 0.9573 - val_loss: 0.1380 - val_acc: 0.9559\n",
      "Train on 779563 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779563/779563 [==============================] - 4s 5us/step - loss: 0.1347 - acc: 0.9568 - val_loss: 0.1330 - val_acc: 0.9572\n",
      "Train on 778857 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778857/778857 [==============================] - 4s 5us/step - loss: 0.1326 - acc: 0.9574 - val_loss: 0.1335 - val_acc: 0.9572\n",
      "Train on 779375 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779375/779375 [==============================] - 3s 4us/step - loss: 0.1336 - acc: 0.9570 - val_loss: 0.1313 - val_acc: 0.9576\n",
      "Train on 778470 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778470/778470 [==============================] - 4s 5us/step - loss: 0.1327 - acc: 0.9574 - val_loss: 0.1380 - val_acc: 0.9560\n",
      "Train on 778737 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778737/778737 [==============================] - 3s 4us/step - loss: 0.1336 - acc: 0.9571 - val_loss: 0.1325 - val_acc: 0.9578\n",
      "Train on 778879 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778879/778879 [==============================] - 4s 5us/step - loss: 0.1327 - acc: 0.9572 - val_loss: 0.1320 - val_acc: 0.9577\n",
      "Train on 779016 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779016/779016 [==============================] - 4s 5us/step - loss: 0.1333 - acc: 0.9571 - val_loss: 0.1308 - val_acc: 0.9578\n",
      "Train on 778957 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778957/778957 [==============================] - 3s 4us/step - loss: 0.1326 - acc: 0.9573 - val_loss: 0.1310 - val_acc: 0.9581\n",
      "Train on 779749 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779749/779749 [==============================] - 4s 5us/step - loss: 0.1336 - acc: 0.9571 - val_loss: 0.1332 - val_acc: 0.9574\n",
      "Train on 778719 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778719/778719 [==============================] - 3s 4us/step - loss: 0.1334 - acc: 0.9571 - val_loss: 0.1332 - val_acc: 0.9570\n",
      "Train on 778558 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778558/778558 [==============================] - 3s 4us/step - loss: 0.1326 - acc: 0.9575 - val_loss: 0.1334 - val_acc: 0.9567\n",
      "Train on 779340 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779340/779340 [==============================] - 4s 5us/step - loss: 0.1328 - acc: 0.9573 - val_loss: 0.1308 - val_acc: 0.9579\n",
      "Train on 778973 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778973/778973 [==============================] - 4s 5us/step - loss: 0.1327 - acc: 0.9574 - val_loss: 0.1322 - val_acc: 0.9574\n",
      "Train on 779520 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779520/779520 [==============================] - 4s 5us/step - loss: 0.1332 - acc: 0.9572 - val_loss: 0.1317 - val_acc: 0.9574\n",
      "Train on 778736 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778736/778736 [==============================] - 4s 5us/step - loss: 0.1326 - acc: 0.9575 - val_loss: 0.1317 - val_acc: 0.9579\n",
      "Train on 779589 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779589/779589 [==============================] - 4s 5us/step - loss: 0.1326 - acc: 0.9573 - val_loss: 0.1339 - val_acc: 0.9569\n",
      "Train on 779154 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779154/779154 [==============================] - 4s 5us/step - loss: 0.1326 - acc: 0.9575 - val_loss: 0.1318 - val_acc: 0.9575\n",
      "Train on 779403 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779403/779403 [==============================] - 3s 4us/step - loss: 0.1322 - acc: 0.9574 - val_loss: 0.1307 - val_acc: 0.9580\n",
      "Train on 778954 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778954/778954 [==============================] - 4s 5us/step - loss: 0.1322 - acc: 0.9574 - val_loss: 0.1321 - val_acc: 0.9576\n",
      "Train on 778485 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778485/778485 [==============================] - 4s 5us/step - loss: 0.1325 - acc: 0.9573 - val_loss: 0.1337 - val_acc: 0.9562\n",
      "Train on 778674 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778674/778674 [==============================] - 4s 5us/step - loss: 0.1329 - acc: 0.9573 - val_loss: 0.1320 - val_acc: 0.9573\n",
      "Train on 779090 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779090/779090 [==============================] - 4s 5us/step - loss: 0.1325 - acc: 0.9574 - val_loss: 0.1307 - val_acc: 0.9581\n",
      "Train on 779475 samples, validate on 193733 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "779475/779475 [==============================] - 3s 4us/step - loss: 0.1328 - acc: 0.9573 - val_loss: 0.1314 - val_acc: 0.9576\n",
      "Train on 779085 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779085/779085 [==============================] - 4s 5us/step - loss: 0.1315 - acc: 0.9576 - val_loss: 0.1313 - val_acc: 0.9580\n",
      "Train on 779370 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779370/779370 [==============================] - 3s 4us/step - loss: 0.1326 - acc: 0.9575 - val_loss: 0.1305 - val_acc: 0.9583\n",
      "Train on 778674 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778674/778674 [==============================] - 3s 4us/step - loss: 0.1321 - acc: 0.9575 - val_loss: 0.1342 - val_acc: 0.9564\n",
      "Train on 779759 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779759/779759 [==============================] - 3s 4us/step - loss: 0.1322 - acc: 0.9573 - val_loss: 0.1303 - val_acc: 0.9580\n",
      "Train on 779373 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779373/779373 [==============================] - 3s 4us/step - loss: 0.1320 - acc: 0.9574 - val_loss: 0.1308 - val_acc: 0.9578\n",
      "Train on 779203 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779203/779203 [==============================] - 3s 4us/step - loss: 0.1318 - acc: 0.9574 - val_loss: 0.1302 - val_acc: 0.9582\n",
      "Train on 778564 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778564/778564 [==============================] - 3s 4us/step - loss: 0.1318 - acc: 0.9574 - val_loss: 0.1334 - val_acc: 0.9569\n",
      "Train on 778240 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778240/778240 [==============================] - 3s 4us/step - loss: 0.1325 - acc: 0.9573 - val_loss: 0.1307 - val_acc: 0.9579\n",
      "Train on 779058 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779058/779058 [==============================] - 3s 4us/step - loss: 0.1313 - acc: 0.9576 - val_loss: 0.1303 - val_acc: 0.9584\n",
      "Train on 778805 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778805/778805 [==============================] - 3s 4us/step - loss: 0.1312 - acc: 0.9577 - val_loss: 0.1309 - val_acc: 0.9579\n",
      "Train on 778622 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778622/778622 [==============================] - 3s 4us/step - loss: 0.1321 - acc: 0.9574 - val_loss: 0.1326 - val_acc: 0.9575\n",
      "Train on 778658 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778658/778658 [==============================] - 3s 4us/step - loss: 0.1326 - acc: 0.9573 - val_loss: 0.1308 - val_acc: 0.9578\n",
      "Train on 779219 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779219/779219 [==============================] - 3s 4us/step - loss: 0.1311 - acc: 0.9578 - val_loss: 0.1307 - val_acc: 0.9580\n",
      "Train on 778476 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778476/778476 [==============================] - 3s 4us/step - loss: 0.1316 - acc: 0.9576 - val_loss: 0.1305 - val_acc: 0.9581\n",
      "Train on 778217 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778217/778217 [==============================] - 3s 4us/step - loss: 0.1316 - acc: 0.9576 - val_loss: 0.1307 - val_acc: 0.9583\n",
      "Train on 779534 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779534/779534 [==============================] - 3s 4us/step - loss: 0.1315 - acc: 0.9576 - val_loss: 0.1299 - val_acc: 0.9583\n",
      "Train on 778508 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778508/778508 [==============================] - 3s 4us/step - loss: 0.1316 - acc: 0.9576 - val_loss: 0.1318 - val_acc: 0.9575\n",
      "Train on 778606 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778606/778606 [==============================] - 3s 4us/step - loss: 0.1320 - acc: 0.9574 - val_loss: 0.1295 - val_acc: 0.9584\n",
      "Train on 778737 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778737/778737 [==============================] - 4s 5us/step - loss: 0.1316 - acc: 0.9576 - val_loss: 0.1318 - val_acc: 0.9577\n",
      "Train on 779089 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779089/779089 [==============================] - 4s 5us/step - loss: 0.1320 - acc: 0.9575 - val_loss: 0.1296 - val_acc: 0.9583\n",
      "Train on 778284 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778284/778284 [==============================] - 3s 4us/step - loss: 0.1309 - acc: 0.9579 - val_loss: 0.1297 - val_acc: 0.9584\n",
      "Train on 777881 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777881/777881 [==============================] - 3s 4us/step - loss: 0.1307 - acc: 0.9579 - val_loss: 0.1289 - val_acc: 0.9585\n",
      "Train on 779086 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779086/779086 [==============================] - 3s 4us/step - loss: 0.1305 - acc: 0.9579 - val_loss: 0.1300 - val_acc: 0.9582\n",
      "Train on 778657 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778657/778657 [==============================] - 3s 4us/step - loss: 0.1311 - acc: 0.9577 - val_loss: 0.1294 - val_acc: 0.9584\n",
      "Train on 779289 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779289/779289 [==============================] - 3s 4us/step - loss: 0.1312 - acc: 0.9578 - val_loss: 0.1294 - val_acc: 0.9585\n",
      "Train on 778601 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778601/778601 [==============================] - 4s 5us/step - loss: 0.1311 - acc: 0.9578 - val_loss: 0.1311 - val_acc: 0.9579\n",
      "Train on 778575 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778575/778575 [==============================] - 3s 4us/step - loss: 0.1308 - acc: 0.9577 - val_loss: 0.1312 - val_acc: 0.9574\n",
      "Train on 778418 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778418/778418 [==============================] - 3s 4us/step - loss: 0.1308 - acc: 0.9578 - val_loss: 0.1307 - val_acc: 0.9582\n",
      "Train on 779219 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779219/779219 [==============================] - 3s 4us/step - loss: 0.1316 - acc: 0.9574 - val_loss: 0.1302 - val_acc: 0.9582\n",
      "Train on 778257 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778257/778257 [==============================] - 3s 4us/step - loss: 0.1308 - acc: 0.9577 - val_loss: 0.1530 - val_acc: 0.9494\n",
      "Train on 779204 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779204/779204 [==============================] - 3s 4us/step - loss: 0.1364 - acc: 0.9562 - val_loss: 0.1295 - val_acc: 0.9584\n",
      "Train on 778477 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778477/778477 [==============================] - 3s 4us/step - loss: 0.1310 - acc: 0.9578 - val_loss: 0.1328 - val_acc: 0.9573\n",
      "Train on 778696 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778696/778696 [==============================] - 3s 4us/step - loss: 0.1308 - acc: 0.9579 - val_loss: 0.1302 - val_acc: 0.9581\n",
      "Train on 778463 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778463/778463 [==============================] - 3s 4us/step - loss: 0.1316 - acc: 0.9576 - val_loss: 0.1304 - val_acc: 0.9577\n",
      "Train on 778742 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778742/778742 [==============================] - 4s 5us/step - loss: 0.1302 - acc: 0.9578 - val_loss: 0.1290 - val_acc: 0.9588\n",
      "Train on 779012 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779012/779012 [==============================] - 4s 5us/step - loss: 0.1302 - acc: 0.9581 - val_loss: 0.1287 - val_acc: 0.9585\n",
      "Train on 778936 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778936/778936 [==============================] - 3s 4us/step - loss: 0.1307 - acc: 0.9580 - val_loss: 0.1293 - val_acc: 0.9583\n",
      "Train on 779364 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779364/779364 [==============================] - 3s 4us/step - loss: 0.1301 - acc: 0.9582 - val_loss: 0.1290 - val_acc: 0.9586\n",
      "Train on 778619 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778619/778619 [==============================] - 3s 4us/step - loss: 0.1305 - acc: 0.9580 - val_loss: 0.1317 - val_acc: 0.9570\n",
      "Train on 779940 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779940/779940 [==============================] - 3s 4us/step - loss: 0.1306 - acc: 0.9577 - val_loss: 0.1287 - val_acc: 0.9588\n",
      "Train on 779450 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779450/779450 [==============================] - 3s 4us/step - loss: 0.1306 - acc: 0.9581 - val_loss: 0.1297 - val_acc: 0.9582\n",
      "Train on 778280 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778280/778280 [==============================] - 3s 4us/step - loss: 0.1301 - acc: 0.9583 - val_loss: 0.1399 - val_acc: 0.9550\n",
      "Train on 778854 samples, validate on 193733 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778854/778854 [==============================] - 3s 4us/step - loss: 0.1322 - acc: 0.9574 - val_loss: 0.1297 - val_acc: 0.9582\n",
      "Train on 779982 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779982/779982 [==============================] - 3s 4us/step - loss: 0.1304 - acc: 0.9581 - val_loss: 0.1297 - val_acc: 0.9582\n",
      "Train on 778534 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778534/778534 [==============================] - 3s 4us/step - loss: 0.1304 - acc: 0.9578 - val_loss: 0.1296 - val_acc: 0.9579\n",
      "Train on 779710 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779710/779710 [==============================] - 3s 4us/step - loss: 0.1299 - acc: 0.9580 - val_loss: 0.1286 - val_acc: 0.9586\n",
      "Train on 779093 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779093/779093 [==============================] - 3s 4us/step - loss: 0.1296 - acc: 0.9581 - val_loss: 0.1291 - val_acc: 0.9585\n",
      "Train on 778791 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778791/778791 [==============================] - 3s 4us/step - loss: 0.1299 - acc: 0.9582 - val_loss: 0.1290 - val_acc: 0.9585\n",
      "Train on 778035 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778035/778035 [==============================] - 4s 5us/step - loss: 0.1300 - acc: 0.9582 - val_loss: 0.1285 - val_acc: 0.9585\n",
      "Train on 779327 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779327/779327 [==============================] - 4s 5us/step - loss: 0.1300 - acc: 0.9580 - val_loss: 0.1291 - val_acc: 0.9584\n",
      "Train on 779408 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779408/779408 [==============================] - 4s 5us/step - loss: 0.1294 - acc: 0.9584 - val_loss: 0.1284 - val_acc: 0.9586\n",
      "Train on 780274 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "780274/780274 [==============================] - 4s 5us/step - loss: 0.1297 - acc: 0.9580 - val_loss: 0.1294 - val_acc: 0.9586\n",
      "Train on 779922 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779922/779922 [==============================] - 3s 4us/step - loss: 0.1305 - acc: 0.9580 - val_loss: 0.1280 - val_acc: 0.9588\n",
      "Train on 778749 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778749/778749 [==============================] - 3s 4us/step - loss: 0.1302 - acc: 0.9581 - val_loss: 0.1295 - val_acc: 0.9585\n",
      "Train on 778595 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778595/778595 [==============================] - 4s 5us/step - loss: 0.1301 - acc: 0.9582 - val_loss: 0.1329 - val_acc: 0.9575\n",
      "Train on 779278 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779278/779278 [==============================] - 4s 5us/step - loss: 0.1303 - acc: 0.9580 - val_loss: 0.1281 - val_acc: 0.9589\n",
      "Train on 779309 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779309/779309 [==============================] - 4s 5us/step - loss: 0.1296 - acc: 0.9581 - val_loss: 0.1278 - val_acc: 0.9589\n",
      "Train on 778685 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778685/778685 [==============================] - 4s 5us/step - loss: 0.1293 - acc: 0.9584 - val_loss: 0.1276 - val_acc: 0.9589\n",
      "Train on 779404 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779404/779404 [==============================] - 4s 5us/step - loss: 0.1295 - acc: 0.9582 - val_loss: 0.1273 - val_acc: 0.9590\n",
      "Train on 778867 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778867/778867 [==============================] - 4s 5us/step - loss: 0.1296 - acc: 0.9584 - val_loss: 0.1288 - val_acc: 0.9587\n",
      "Train on 779574 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779574/779574 [==============================] - 4s 5us/step - loss: 0.1300 - acc: 0.9581 - val_loss: 0.1282 - val_acc: 0.9588\n",
      "Train on 778831 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778831/778831 [==============================] - 4s 5us/step - loss: 0.1297 - acc: 0.9582 - val_loss: 0.1314 - val_acc: 0.9580\n",
      "Train on 779666 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779666/779666 [==============================] - 3s 4us/step - loss: 0.1300 - acc: 0.9581 - val_loss: 0.1276 - val_acc: 0.9590\n",
      "Train on 779379 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779379/779379 [==============================] - 4s 5us/step - loss: 0.1287 - acc: 0.9584 - val_loss: 0.1276 - val_acc: 0.9590\n",
      "Train on 778345 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778345/778345 [==============================] - 4s 5us/step - loss: 0.1295 - acc: 0.9581 - val_loss: 0.1305 - val_acc: 0.9577\n",
      "Train on 778467 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778467/778467 [==============================] - 4s 5us/step - loss: 0.1296 - acc: 0.9581 - val_loss: 0.1282 - val_acc: 0.9588\n",
      "Train on 779011 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779011/779011 [==============================] - 4s 5us/step - loss: 0.1295 - acc: 0.9581 - val_loss: 0.1295 - val_acc: 0.9583\n",
      "Train on 779297 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779297/779297 [==============================] - 5s 6us/step - loss: 0.1295 - acc: 0.9581 - val_loss: 0.1287 - val_acc: 0.9585\n",
      "Train on 780238 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "780238/780238 [==============================] - 5s 7us/step - loss: 0.1286 - acc: 0.9585 - val_loss: 0.1277 - val_acc: 0.9588\n",
      "Train on 778258 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778258/778258 [==============================] - 4s 5us/step - loss: 0.1290 - acc: 0.9583 - val_loss: 0.1364 - val_acc: 0.9567\n",
      "Train on 778546 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778546/778546 [==============================] - 4s 5us/step - loss: 0.1323 - acc: 0.9575 - val_loss: 0.1285 - val_acc: 0.9587\n",
      "Train on 778092 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778092/778092 [==============================] - 4s 5us/step - loss: 0.1298 - acc: 0.9584 - val_loss: 0.1275 - val_acc: 0.9588\n",
      "Train on 778911 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778911/778911 [==============================] - 4s 5us/step - loss: 0.1289 - acc: 0.9585 - val_loss: 0.1274 - val_acc: 0.9589\n",
      "Train on 779021 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779021/779021 [==============================] - 3s 4us/step - loss: 0.1297 - acc: 0.9582 - val_loss: 0.1287 - val_acc: 0.9587\n",
      "Train on 779146 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779146/779146 [==============================] - 4s 5us/step - loss: 0.1294 - acc: 0.9583 - val_loss: 0.1282 - val_acc: 0.9587\n",
      "Train on 778713 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778713/778713 [==============================] - 4s 5us/step - loss: 0.1294 - acc: 0.9583 - val_loss: 0.1290 - val_acc: 0.9584\n",
      "Train on 778197 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778197/778197 [==============================] - 3s 4us/step - loss: 0.1288 - acc: 0.9585 - val_loss: 0.1272 - val_acc: 0.9592\n",
      "Train on 778197 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778197/778197 [==============================] - 3s 4us/step - loss: 0.1285 - acc: 0.9584 - val_loss: 0.1271 - val_acc: 0.9590\n",
      "Train on 779000 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779000/779000 [==============================] - 3s 4us/step - loss: 0.1294 - acc: 0.9583 - val_loss: 0.1277 - val_acc: 0.9590\n",
      "Train on 778597 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778597/778597 [==============================] - 3s 4us/step - loss: 0.1294 - acc: 0.9585 - val_loss: 0.1316 - val_acc: 0.9574\n",
      "Train on 779688 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779688/779688 [==============================] - 3s 4us/step - loss: 0.1298 - acc: 0.9581 - val_loss: 0.1273 - val_acc: 0.9591\n",
      "Train on 778987 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778987/778987 [==============================] - 3s 4us/step - loss: 0.1294 - acc: 0.9582 - val_loss: 0.1302 - val_acc: 0.9580\n",
      "Train on 779027 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779027/779027 [==============================] - 3s 4us/step - loss: 0.1284 - acc: 0.9584 - val_loss: 0.1275 - val_acc: 0.9591\n",
      "Train on 778722 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778722/778722 [==============================] - 3s 4us/step - loss: 0.1293 - acc: 0.9583 - val_loss: 0.1289 - val_acc: 0.9585\n",
      "Train on 778794 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778794/778794 [==============================] - 3s 4us/step - loss: 0.1289 - acc: 0.9585 - val_loss: 0.1272 - val_acc: 0.9593\n",
      "Train on 778524 samples, validate on 193733 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778524/778524 [==============================] - 4s 5us/step - loss: 0.1286 - acc: 0.9585 - val_loss: 0.1272 - val_acc: 0.9589\n",
      "Train on 778768 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778768/778768 [==============================] - 4s 5us/step - loss: 0.1295 - acc: 0.9582 - val_loss: 0.1282 - val_acc: 0.9586\n",
      "Train on 779376 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779376/779376 [==============================] - 3s 4us/step - loss: 0.1289 - acc: 0.9583 - val_loss: 0.1282 - val_acc: 0.9590\n",
      "Train on 778306 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778306/778306 [==============================] - 4s 5us/step - loss: 0.1290 - acc: 0.9585 - val_loss: 0.1272 - val_acc: 0.9589\n",
      "Train on 778622 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778622/778622 [==============================] - 4s 5us/step - loss: 0.1286 - acc: 0.9586 - val_loss: 0.1280 - val_acc: 0.9589\n",
      "Train on 779562 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779562/779562 [==============================] - 3s 4us/step - loss: 0.1289 - acc: 0.9585 - val_loss: 0.1272 - val_acc: 0.9590\n",
      "Train on 778356 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778356/778356 [==============================] - 3s 4us/step - loss: 0.1284 - acc: 0.9587 - val_loss: 0.1334 - val_acc: 0.9563\n",
      "Train on 778637 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778637/778637 [==============================] - 4s 5us/step - loss: 0.1299 - acc: 0.9581 - val_loss: 0.1279 - val_acc: 0.9587\n",
      "Train on 778263 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778263/778263 [==============================] - 4s 5us/step - loss: 0.1286 - acc: 0.9587 - val_loss: 0.1333 - val_acc: 0.9575\n",
      "Train on 778645 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778645/778645 [==============================] - 4s 5us/step - loss: 0.1308 - acc: 0.9579 - val_loss: 0.1280 - val_acc: 0.9586\n",
      "Train on 779615 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779615/779615 [==============================] - 4s 5us/step - loss: 0.1292 - acc: 0.9583 - val_loss: 0.1282 - val_acc: 0.9587\n",
      "Train on 779248 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779248/779248 [==============================] - 3s 4us/step - loss: 0.1288 - acc: 0.9586 - val_loss: 0.1265 - val_acc: 0.9593\n",
      "Train on 779641 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779641/779641 [==============================] - 3s 4us/step - loss: 0.1290 - acc: 0.9586 - val_loss: 0.1267 - val_acc: 0.9593\n",
      "Train on 778868 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778868/778868 [==============================] - 3s 4us/step - loss: 0.1281 - acc: 0.9587 - val_loss: 0.1275 - val_acc: 0.9588\n",
      "Train on 778898 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778898/778898 [==============================] - 3s 4us/step - loss: 0.1284 - acc: 0.9586 - val_loss: 0.1276 - val_acc: 0.9588\n",
      "Train on 779572 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779572/779572 [==============================] - 3s 4us/step - loss: 0.1279 - acc: 0.9586 - val_loss: 0.1273 - val_acc: 0.9591\n",
      "Train on 779191 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779191/779191 [==============================] - 3s 4us/step - loss: 0.1284 - acc: 0.9586 - val_loss: 0.1271 - val_acc: 0.9592\n",
      "Train on 778969 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778969/778969 [==============================] - 3s 4us/step - loss: 0.1286 - acc: 0.9586 - val_loss: 0.1272 - val_acc: 0.9593\n",
      "Train on 779796 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779796/779796 [==============================] - 3s 4us/step - loss: 0.1283 - acc: 0.9587 - val_loss: 0.1268 - val_acc: 0.9593\n",
      "Train on 778927 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778927/778927 [==============================] - 3s 4us/step - loss: 0.1278 - acc: 0.9587 - val_loss: 0.1271 - val_acc: 0.9589\n",
      "Train on 777854 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777854/777854 [==============================] - 3s 4us/step - loss: 0.1281 - acc: 0.9589 - val_loss: 0.1267 - val_acc: 0.9593\n",
      "Train on 780280 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "780280/780280 [==============================] - 3s 4us/step - loss: 0.1277 - acc: 0.9589 - val_loss: 0.1263 - val_acc: 0.9595\n",
      "Train on 779099 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779099/779099 [==============================] - 3s 4us/step - loss: 0.1283 - acc: 0.9586 - val_loss: 0.1269 - val_acc: 0.9595\n",
      "Train on 779646 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779646/779646 [==============================] - 3s 4us/step - loss: 0.1285 - acc: 0.9586 - val_loss: 0.1270 - val_acc: 0.9594\n",
      "Train on 778967 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778967/778967 [==============================] - 3s 4us/step - loss: 0.1277 - acc: 0.9588 - val_loss: 0.1273 - val_acc: 0.9587\n",
      "Train on 778587 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778587/778587 [==============================] - 3s 4us/step - loss: 0.1284 - acc: 0.9588 - val_loss: 0.1286 - val_acc: 0.9583\n",
      "Train on 778851 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778851/778851 [==============================] - 3s 4us/step - loss: 0.1285 - acc: 0.9584 - val_loss: 0.1270 - val_acc: 0.9592\n",
      "Train on 779523 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779523/779523 [==============================] - 3s 4us/step - loss: 0.1282 - acc: 0.9588 - val_loss: 0.1270 - val_acc: 0.9593\n",
      "Train on 777943 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777943/777943 [==============================] - 3s 4us/step - loss: 0.1279 - acc: 0.9587 - val_loss: 0.1262 - val_acc: 0.9594\n",
      "Train on 778568 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778568/778568 [==============================] - 3s 4us/step - loss: 0.1285 - acc: 0.9587 - val_loss: 0.1265 - val_acc: 0.9595\n",
      "Train on 779204 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779204/779204 [==============================] - 3s 4us/step - loss: 0.1281 - acc: 0.9589 - val_loss: 0.1266 - val_acc: 0.9593\n",
      "Train on 778712 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778712/778712 [==============================] - 3s 4us/step - loss: 0.1280 - acc: 0.9589 - val_loss: 0.1266 - val_acc: 0.9590\n",
      "Train on 777920 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777920/777920 [==============================] - 3s 4us/step - loss: 0.1276 - acc: 0.9588 - val_loss: 0.1269 - val_acc: 0.9589\n",
      "Train on 780461 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "780461/780461 [==============================] - 3s 4us/step - loss: 0.1279 - acc: 0.9588 - val_loss: 0.1261 - val_acc: 0.9593\n",
      "Train on 779175 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779175/779175 [==============================] - 3s 4us/step - loss: 0.1278 - acc: 0.9588 - val_loss: 0.1270 - val_acc: 0.9592\n",
      "Train on 779465 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779465/779465 [==============================] - 3s 4us/step - loss: 0.1280 - acc: 0.9590 - val_loss: 0.1260 - val_acc: 0.9596\n",
      "Train on 779790 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779790/779790 [==============================] - 3s 4us/step - loss: 0.1278 - acc: 0.9588 - val_loss: 0.1269 - val_acc: 0.9593\n",
      "Train on 777458 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777458/777458 [==============================] - 3s 4us/step - loss: 0.1271 - acc: 0.9590 - val_loss: 0.1266 - val_acc: 0.9591\n",
      "Train on 780212 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "780212/780212 [==============================] - 3s 4us/step - loss: 0.1272 - acc: 0.9590 - val_loss: 0.1273 - val_acc: 0.9590\n",
      "Train on 778397 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778397/778397 [==============================] - 3s 4us/step - loss: 0.1273 - acc: 0.9590 - val_loss: 0.1310 - val_acc: 0.9581\n",
      "Train on 779246 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779246/779246 [==============================] - 3s 4us/step - loss: 0.1286 - acc: 0.9586 - val_loss: 0.1263 - val_acc: 0.9594\n",
      "Train on 778930 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778930/778930 [==============================] - 3s 4us/step - loss: 0.1272 - acc: 0.9590 - val_loss: 0.1261 - val_acc: 0.9595\n",
      "Train on 779892 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779892/779892 [==============================] - 3s 4us/step - loss: 0.1272 - acc: 0.9591 - val_loss: 0.1265 - val_acc: 0.9595\n",
      "Train on 779107 samples, validate on 193733 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "779107/779107 [==============================] - 3s 4us/step - loss: 0.1277 - acc: 0.9590 - val_loss: 0.1258 - val_acc: 0.9596\n",
      "Train on 778820 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778820/778820 [==============================] - 3s 4us/step - loss: 0.1273 - acc: 0.9589 - val_loss: 0.1263 - val_acc: 0.9596\n",
      "Train on 779406 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779406/779406 [==============================] - 3s 4us/step - loss: 0.1273 - acc: 0.9589 - val_loss: 0.1260 - val_acc: 0.9595\n",
      "Train on 777608 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777608/777608 [==============================] - 3s 4us/step - loss: 0.1270 - acc: 0.9590 - val_loss: 0.1261 - val_acc: 0.9592\n",
      "Train on 778921 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778921/778921 [==============================] - 3s 4us/step - loss: 0.1276 - acc: 0.9589 - val_loss: 0.1266 - val_acc: 0.9592\n",
      "Train on 779288 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779288/779288 [==============================] - 3s 4us/step - loss: 0.1275 - acc: 0.9589 - val_loss: 0.1262 - val_acc: 0.9594\n",
      "Train on 779155 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779155/779155 [==============================] - 3s 4us/step - loss: 0.1274 - acc: 0.9590 - val_loss: 0.1256 - val_acc: 0.9597\n",
      "Train on 779068 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779068/779068 [==============================] - 3s 4us/step - loss: 0.1279 - acc: 0.9588 - val_loss: 0.1260 - val_acc: 0.9596\n",
      "Train on 779027 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779027/779027 [==============================] - 3s 4us/step - loss: 0.1268 - acc: 0.9589 - val_loss: 0.1269 - val_acc: 0.9593\n",
      "Train on 778795 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778795/778795 [==============================] - 3s 4us/step - loss: 0.1274 - acc: 0.9589 - val_loss: 0.1274 - val_acc: 0.9590\n",
      "Train on 778721 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778721/778721 [==============================] - 3s 4us/step - loss: 0.1273 - acc: 0.9589 - val_loss: 0.1272 - val_acc: 0.9591\n",
      "Train on 779322 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779322/779322 [==============================] - 3s 4us/step - loss: 0.1276 - acc: 0.9589 - val_loss: 0.1261 - val_acc: 0.9595\n",
      "Train on 778184 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778184/778184 [==============================] - 3s 4us/step - loss: 0.1273 - acc: 0.9591 - val_loss: 0.1256 - val_acc: 0.9596\n",
      "Train on 778721 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778721/778721 [==============================] - 3s 4us/step - loss: 0.1272 - acc: 0.9590 - val_loss: 0.1283 - val_acc: 0.9588\n",
      "Train on 779705 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779705/779705 [==============================] - 3s 4us/step - loss: 0.1278 - acc: 0.9587 - val_loss: 0.1263 - val_acc: 0.9597\n",
      "Train on 777312 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777312/777312 [==============================] - 3s 4us/step - loss: 0.1268 - acc: 0.9589 - val_loss: 0.1254 - val_acc: 0.9596\n",
      "Train on 778517 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778517/778517 [==============================] - 3s 4us/step - loss: 0.1270 - acc: 0.9591 - val_loss: 0.1281 - val_acc: 0.9589\n",
      "Train on 778939 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778939/778939 [==============================] - 3s 4us/step - loss: 0.1272 - acc: 0.9591 - val_loss: 0.1255 - val_acc: 0.9598\n",
      "Train on 778913 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778913/778913 [==============================] - 3s 4us/step - loss: 0.1272 - acc: 0.9591 - val_loss: 0.1256 - val_acc: 0.9595\n",
      "Train on 778897 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778897/778897 [==============================] - 3s 4us/step - loss: 0.1264 - acc: 0.9592 - val_loss: 0.1260 - val_acc: 0.9594\n",
      "Train on 779161 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779161/779161 [==============================] - 3s 4us/step - loss: 0.1276 - acc: 0.9590 - val_loss: 0.1264 - val_acc: 0.9593\n",
      "Train on 778812 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778812/778812 [==============================] - 3s 4us/step - loss: 0.1281 - acc: 0.9587 - val_loss: 0.1270 - val_acc: 0.9590\n",
      "Train on 779546 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779546/779546 [==============================] - 3s 4us/step - loss: 0.1278 - acc: 0.9590 - val_loss: 0.1262 - val_acc: 0.9593\n",
      "Train on 779487 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779487/779487 [==============================] - 3s 4us/step - loss: 0.1272 - acc: 0.9590 - val_loss: 0.1269 - val_acc: 0.9590\n",
      "Train on 779357 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779357/779357 [==============================] - 4s 5us/step - loss: 0.1270 - acc: 0.9592 - val_loss: 0.1264 - val_acc: 0.9591\n",
      "Train on 778617 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778617/778617 [==============================] - 4s 5us/step - loss: 0.1278 - acc: 0.9589 - val_loss: 0.1269 - val_acc: 0.9592\n",
      "Train on 778948 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778948/778948 [==============================] - 3s 4us/step - loss: 0.1274 - acc: 0.9590 - val_loss: 0.1259 - val_acc: 0.9595\n",
      "Train on 778802 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778802/778802 [==============================] - 3s 4us/step - loss: 0.1265 - acc: 0.9593 - val_loss: 0.1258 - val_acc: 0.9595\n",
      "Train on 779604 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779604/779604 [==============================] - 3s 4us/step - loss: 0.1271 - acc: 0.9590 - val_loss: 0.1258 - val_acc: 0.9594\n",
      "Train on 780517 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "780517/780517 [==============================] - 3s 4us/step - loss: 0.1268 - acc: 0.9590 - val_loss: 0.1249 - val_acc: 0.9598\n",
      "Train on 779546 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779546/779546 [==============================] - 3s 4us/step - loss: 0.1268 - acc: 0.9591 - val_loss: 0.1257 - val_acc: 0.9594\n",
      "Train on 779892 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779892/779892 [==============================] - 3s 4us/step - loss: 0.1271 - acc: 0.9592 - val_loss: 0.1268 - val_acc: 0.9592\n",
      "Train on 779532 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779532/779532 [==============================] - 3s 4us/step - loss: 0.1273 - acc: 0.9592 - val_loss: 0.1260 - val_acc: 0.9597\n",
      "Train on 779402 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779402/779402 [==============================] - 3s 4us/step - loss: 0.1261 - acc: 0.9593 - val_loss: 0.1252 - val_acc: 0.9598\n",
      "Train on 779323 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779323/779323 [==============================] - 3s 4us/step - loss: 0.1268 - acc: 0.9591 - val_loss: 0.1261 - val_acc: 0.9594\n",
      "Train on 779611 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779611/779611 [==============================] - 3s 4us/step - loss: 0.1263 - acc: 0.9592 - val_loss: 0.1263 - val_acc: 0.9594\n",
      "Train on 779353 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779353/779353 [==============================] - 3s 4us/step - loss: 0.1266 - acc: 0.9591 - val_loss: 0.1261 - val_acc: 0.9593\n",
      "Train on 779257 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779257/779257 [==============================] - 3s 4us/step - loss: 0.1267 - acc: 0.9592 - val_loss: 0.1256 - val_acc: 0.9595\n",
      "Train on 778817 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778817/778817 [==============================] - 3s 4us/step - loss: 0.1265 - acc: 0.9594 - val_loss: 0.1268 - val_acc: 0.9589\n",
      "Train on 778964 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778964/778964 [==============================] - 3s 4us/step - loss: 0.1271 - acc: 0.9589 - val_loss: 0.1261 - val_acc: 0.9596\n",
      "Train on 779110 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779110/779110 [==============================] - 3s 4us/step - loss: 0.1263 - acc: 0.9592 - val_loss: 0.1264 - val_acc: 0.9597\n",
      "Train on 779419 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779419/779419 [==============================] - 3s 4us/step - loss: 0.1267 - acc: 0.9591 - val_loss: 0.1257 - val_acc: 0.9596\n",
      "Train on 778145 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778145/778145 [==============================] - 3s 4us/step - loss: 0.1272 - acc: 0.9590 - val_loss: 0.1255 - val_acc: 0.9596\n",
      "Train on 779501 samples, validate on 193733 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "779501/779501 [==============================] - 3s 4us/step - loss: 0.1265 - acc: 0.9591 - val_loss: 0.1267 - val_acc: 0.9591\n",
      "Train on 779603 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779603/779603 [==============================] - 3s 4us/step - loss: 0.1270 - acc: 0.9590 - val_loss: 0.1272 - val_acc: 0.9590\n",
      "Train on 778672 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778672/778672 [==============================] - 3s 4us/step - loss: 0.1259 - acc: 0.9592 - val_loss: 0.1251 - val_acc: 0.9598\n",
      "Train on 778923 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778923/778923 [==============================] - 3s 4us/step - loss: 0.1264 - acc: 0.9593 - val_loss: 0.1275 - val_acc: 0.9590\n",
      "Train on 779252 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779252/779252 [==============================] - 3s 4us/step - loss: 0.1271 - acc: 0.9591 - val_loss: 0.1253 - val_acc: 0.9596\n",
      "Train on 778890 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778890/778890 [==============================] - 3s 4us/step - loss: 0.1262 - acc: 0.9593 - val_loss: 0.1259 - val_acc: 0.9596\n",
      "Train on 779770 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779770/779770 [==============================] - 3s 4us/step - loss: 0.1270 - acc: 0.9590 - val_loss: 0.1258 - val_acc: 0.9595\n",
      "Train on 778813 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778813/778813 [==============================] - 3s 4us/step - loss: 0.1269 - acc: 0.9591 - val_loss: 0.1263 - val_acc: 0.9590\n",
      "Train on 778750 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778750/778750 [==============================] - 3s 4us/step - loss: 0.1267 - acc: 0.9592 - val_loss: 0.1277 - val_acc: 0.9591\n",
      "Train on 779374 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779374/779374 [==============================] - 3s 4us/step - loss: 0.1266 - acc: 0.9590 - val_loss: 0.1253 - val_acc: 0.9597\n",
      "Train on 779335 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779335/779335 [==============================] - 3s 4us/step - loss: 0.1258 - acc: 0.9593 - val_loss: 0.1246 - val_acc: 0.9600\n",
      "Train on 779539 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779539/779539 [==============================] - 3s 4us/step - loss: 0.1263 - acc: 0.9593 - val_loss: 0.1249 - val_acc: 0.9598\n",
      "Train on 778738 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778738/778738 [==============================] - 3s 4us/step - loss: 0.1261 - acc: 0.9594 - val_loss: 0.1255 - val_acc: 0.9597\n",
      "Train on 779191 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779191/779191 [==============================] - 3s 4us/step - loss: 0.1264 - acc: 0.9591 - val_loss: 0.1256 - val_acc: 0.9595\n",
      "Train on 779476 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779476/779476 [==============================] - 3s 4us/step - loss: 0.1263 - acc: 0.9593 - val_loss: 0.1257 - val_acc: 0.9595\n",
      "Train on 778373 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778373/778373 [==============================] - 3s 4us/step - loss: 0.1266 - acc: 0.9593 - val_loss: 0.1278 - val_acc: 0.9587\n",
      "Train on 779259 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779259/779259 [==============================] - 3s 4us/step - loss: 0.1270 - acc: 0.9591 - val_loss: 0.1252 - val_acc: 0.9597\n",
      "Train on 779267 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779267/779267 [==============================] - 3s 4us/step - loss: 0.1266 - acc: 0.9592 - val_loss: 0.1254 - val_acc: 0.9597\n",
      "Train on 780028 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "780028/780028 [==============================] - 3s 4us/step - loss: 0.1257 - acc: 0.9595 - val_loss: 0.1254 - val_acc: 0.9596\n",
      "Train on 778699 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778699/778699 [==============================] - 3s 4us/step - loss: 0.1263 - acc: 0.9594 - val_loss: 0.1247 - val_acc: 0.9598\n",
      "Train on 779314 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779314/779314 [==============================] - 3s 4us/step - loss: 0.1258 - acc: 0.9593 - val_loss: 0.1277 - val_acc: 0.9588\n",
      "Train on 779543 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779543/779543 [==============================] - 3s 4us/step - loss: 0.1262 - acc: 0.9593 - val_loss: 0.1253 - val_acc: 0.9599\n",
      "Train on 778692 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778692/778692 [==============================] - 3s 4us/step - loss: 0.1261 - acc: 0.9593 - val_loss: 0.1261 - val_acc: 0.9597\n",
      "Train on 777740 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777740/777740 [==============================] - 3s 4us/step - loss: 0.1261 - acc: 0.9594 - val_loss: 0.1252 - val_acc: 0.9597\n",
      "Train on 778996 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778996/778996 [==============================] - 3s 4us/step - loss: 0.1258 - acc: 0.9594 - val_loss: 0.1251 - val_acc: 0.9598\n",
      "Train on 779479 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779479/779479 [==============================] - 3s 4us/step - loss: 0.1264 - acc: 0.9593 - val_loss: 0.1252 - val_acc: 0.9597\n",
      "Train on 779369 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779369/779369 [==============================] - 3s 4us/step - loss: 0.1264 - acc: 0.9593 - val_loss: 0.1241 - val_acc: 0.9602\n",
      "Train on 777884 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777884/777884 [==============================] - 3s 4us/step - loss: 0.1265 - acc: 0.9592 - val_loss: 0.1253 - val_acc: 0.9598\n",
      "Train on 779837 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779837/779837 [==============================] - 3s 4us/step - loss: 0.1260 - acc: 0.9594 - val_loss: 0.1247 - val_acc: 0.9600\n",
      "Train on 779200 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779200/779200 [==============================] - 3s 4us/step - loss: 0.1267 - acc: 0.9592 - val_loss: 0.1250 - val_acc: 0.9597\n",
      "Train on 779450 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779450/779450 [==============================] - 3s 4us/step - loss: 0.1261 - acc: 0.9593 - val_loss: 0.1249 - val_acc: 0.9599\n",
      "Train on 779342 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779342/779342 [==============================] - 3s 4us/step - loss: 0.1260 - acc: 0.9595 - val_loss: 0.1253 - val_acc: 0.9598\n",
      "Train on 779064 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779064/779064 [==============================] - 3s 4us/step - loss: 0.1254 - acc: 0.9596 - val_loss: 0.1251 - val_acc: 0.9600\n",
      "Train on 778624 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778624/778624 [==============================] - 3s 4us/step - loss: 0.1260 - acc: 0.9595 - val_loss: 0.1256 - val_acc: 0.9595\n",
      "Train on 778840 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778840/778840 [==============================] - 3s 4us/step - loss: 0.1261 - acc: 0.9595 - val_loss: 0.1255 - val_acc: 0.9592\n",
      "Train on 778388 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778388/778388 [==============================] - 3s 4us/step - loss: 0.1257 - acc: 0.9596 - val_loss: 0.1303 - val_acc: 0.9581\n",
      "Train on 778392 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778392/778392 [==============================] - 3s 4us/step - loss: 0.1263 - acc: 0.9593 - val_loss: 0.1254 - val_acc: 0.9596\n",
      "Train on 779234 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779234/779234 [==============================] - 3s 4us/step - loss: 0.1260 - acc: 0.9594 - val_loss: 0.1273 - val_acc: 0.9591\n",
      "Train on 779296 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779296/779296 [==============================] - 3s 4us/step - loss: 0.1266 - acc: 0.9591 - val_loss: 0.1251 - val_acc: 0.9598\n",
      "Train on 779020 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779020/779020 [==============================] - 3s 4us/step - loss: 0.1262 - acc: 0.9594 - val_loss: 0.1253 - val_acc: 0.9597\n",
      "Train on 778845 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778845/778845 [==============================] - 3s 4us/step - loss: 0.1258 - acc: 0.9596 - val_loss: 0.1245 - val_acc: 0.9599\n",
      "Train on 778567 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778567/778567 [==============================] - 3s 4us/step - loss: 0.1260 - acc: 0.9592 - val_loss: 0.1283 - val_acc: 0.9588\n",
      "Train on 778405 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778405/778405 [==============================] - 3s 4us/step - loss: 0.1259 - acc: 0.9592 - val_loss: 0.1295 - val_acc: 0.9584\n",
      "Train on 779712 samples, validate on 193733 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "779712/779712 [==============================] - 3s 4us/step - loss: 0.1286 - acc: 0.9587 - val_loss: 0.1261 - val_acc: 0.9596\n",
      "Train on 778342 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778342/778342 [==============================] - 3s 4us/step - loss: 0.1259 - acc: 0.9592 - val_loss: 0.1277 - val_acc: 0.9589\n",
      "Train on 779182 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779182/779182 [==============================] - 3s 4us/step - loss: 0.1262 - acc: 0.9593 - val_loss: 0.1260 - val_acc: 0.9594\n",
      "Train on 779088 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779088/779088 [==============================] - 3s 4us/step - loss: 0.1257 - acc: 0.9594 - val_loss: 0.1245 - val_acc: 0.9600\n",
      "Train on 779170 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779170/779170 [==============================] - 3s 4us/step - loss: 0.1256 - acc: 0.9595 - val_loss: 0.1250 - val_acc: 0.9599\n",
      "Train on 778748 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778748/778748 [==============================] - 3s 4us/step - loss: 0.1256 - acc: 0.9594 - val_loss: 0.1251 - val_acc: 0.9597\n",
      "Train on 779231 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779231/779231 [==============================] - 3s 4us/step - loss: 0.1255 - acc: 0.9596 - val_loss: 0.1251 - val_acc: 0.9597\n",
      "Train on 779426 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779426/779426 [==============================] - 3s 4us/step - loss: 0.1257 - acc: 0.9595 - val_loss: 0.1248 - val_acc: 0.9600\n",
      "Train on 777906 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777906/777906 [==============================] - 3s 4us/step - loss: 0.1257 - acc: 0.9595 - val_loss: 0.1241 - val_acc: 0.9602\n",
      "Train on 779033 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779033/779033 [==============================] - 3s 4us/step - loss: 0.1253 - acc: 0.9598 - val_loss: 0.1251 - val_acc: 0.9599\n",
      "Train on 778132 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778132/778132 [==============================] - 3s 4us/step - loss: 0.1258 - acc: 0.9595 - val_loss: 0.1247 - val_acc: 0.9600\n",
      "Train on 779582 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779582/779582 [==============================] - 3s 4us/step - loss: 0.1249 - acc: 0.9598 - val_loss: 0.1245 - val_acc: 0.9600\n",
      "Train on 779117 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779117/779117 [==============================] - 3s 4us/step - loss: 0.1263 - acc: 0.9593 - val_loss: 0.1252 - val_acc: 0.9597\n",
      "Train on 778235 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778235/778235 [==============================] - 3s 4us/step - loss: 0.1259 - acc: 0.9595 - val_loss: 0.1252 - val_acc: 0.9597\n",
      "Train on 777564 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777564/777564 [==============================] - 3s 4us/step - loss: 0.1255 - acc: 0.9595 - val_loss: 0.1240 - val_acc: 0.9601\n",
      "Train on 779493 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779493/779493 [==============================] - 3s 4us/step - loss: 0.1257 - acc: 0.9594 - val_loss: 0.1253 - val_acc: 0.9593\n",
      "Train on 777898 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777898/777898 [==============================] - 3s 4us/step - loss: 0.1263 - acc: 0.9593 - val_loss: 0.1244 - val_acc: 0.9599\n",
      "Train on 778678 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778678/778678 [==============================] - 3s 4us/step - loss: 0.1250 - acc: 0.9596 - val_loss: 0.1252 - val_acc: 0.9596\n",
      "Train on 778588 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778588/778588 [==============================] - 3s 4us/step - loss: 0.1257 - acc: 0.9594 - val_loss: 0.1288 - val_acc: 0.9586\n",
      "Train on 779301 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779301/779301 [==============================] - 3s 4us/step - loss: 0.1261 - acc: 0.9593 - val_loss: 0.1247 - val_acc: 0.9599\n",
      "Train on 778017 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778017/778017 [==============================] - 3s 4us/step - loss: 0.1258 - acc: 0.9593 - val_loss: 0.1249 - val_acc: 0.9599\n",
      "Train on 778000 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778000/778000 [==============================] - 3s 4us/step - loss: 0.1256 - acc: 0.9596 - val_loss: 0.1241 - val_acc: 0.9602\n",
      "Train on 779240 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779240/779240 [==============================] - 3s 4us/step - loss: 0.1249 - acc: 0.9596 - val_loss: 0.1261 - val_acc: 0.9595\n",
      "Train on 778023 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778023/778023 [==============================] - 3s 4us/step - loss: 0.1254 - acc: 0.9596 - val_loss: 0.1249 - val_acc: 0.9597\n",
      "Train on 779012 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779012/779012 [==============================] - 3s 4us/step - loss: 0.1256 - acc: 0.9596 - val_loss: 0.1252 - val_acc: 0.9595\n",
      "Train on 778397 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778397/778397 [==============================] - 3s 4us/step - loss: 0.1248 - acc: 0.9596 - val_loss: 0.1242 - val_acc: 0.9600\n",
      "Train on 778970 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778970/778970 [==============================] - 3s 4us/step - loss: 0.1253 - acc: 0.9598 - val_loss: 0.1244 - val_acc: 0.9601\n",
      "Train on 779216 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779216/779216 [==============================] - 3s 4us/step - loss: 0.1250 - acc: 0.9596 - val_loss: 0.1257 - val_acc: 0.9595\n",
      "Train on 778853 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778853/778853 [==============================] - 3s 4us/step - loss: 0.1249 - acc: 0.9598 - val_loss: 0.1240 - val_acc: 0.9602\n",
      "Train on 779798 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779798/779798 [==============================] - 3s 4us/step - loss: 0.1250 - acc: 0.9596 - val_loss: 0.1243 - val_acc: 0.9600\n",
      "Train on 779060 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779060/779060 [==============================] - 3s 4us/step - loss: 0.1255 - acc: 0.9596 - val_loss: 0.1249 - val_acc: 0.9597\n",
      "Train on 778686 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778686/778686 [==============================] - 3s 4us/step - loss: 0.1255 - acc: 0.9597 - val_loss: 0.1246 - val_acc: 0.9597\n",
      "Train on 778649 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778649/778649 [==============================] - 3s 4us/step - loss: 0.1257 - acc: 0.9594 - val_loss: 0.1236 - val_acc: 0.9602\n",
      "Train on 778370 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778370/778370 [==============================] - 3s 4us/step - loss: 0.1261 - acc: 0.9592 - val_loss: 0.1274 - val_acc: 0.9588\n",
      "Train on 779099 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779099/779099 [==============================] - 3s 4us/step - loss: 0.1261 - acc: 0.9594 - val_loss: 0.1243 - val_acc: 0.9601\n",
      "Train on 778437 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778437/778437 [==============================] - 3s 4us/step - loss: 0.1254 - acc: 0.9595 - val_loss: 0.1245 - val_acc: 0.9599\n",
      "Train on 777786 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777786/777786 [==============================] - 3s 4us/step - loss: 0.1260 - acc: 0.9592 - val_loss: 0.1236 - val_acc: 0.9603\n",
      "Train on 778609 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778609/778609 [==============================] - 3s 4us/step - loss: 0.1249 - acc: 0.9596 - val_loss: 0.1251 - val_acc: 0.9596\n",
      "Train on 779939 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779939/779939 [==============================] - 3s 4us/step - loss: 0.1255 - acc: 0.9596 - val_loss: 0.1242 - val_acc: 0.9603\n",
      "Train on 779586 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779586/779586 [==============================] - 3s 4us/step - loss: 0.1251 - acc: 0.9596 - val_loss: 0.1245 - val_acc: 0.9598\n",
      "Train on 778991 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778991/778991 [==============================] - 3s 4us/step - loss: 0.1248 - acc: 0.9598 - val_loss: 0.1243 - val_acc: 0.9601\n",
      "Train on 778978 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778978/778978 [==============================] - 3s 4us/step - loss: 0.1249 - acc: 0.9596 - val_loss: 0.1238 - val_acc: 0.9603\n",
      "Train on 779015 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779015/779015 [==============================] - 3s 4us/step - loss: 0.1251 - acc: 0.9596 - val_loss: 0.1266 - val_acc: 0.9593\n",
      "Train on 780229 samples, validate on 193733 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780229/780229 [==============================] - 3s 4us/step - loss: 0.1258 - acc: 0.9594 - val_loss: 0.1252 - val_acc: 0.9596\n",
      "Train on 778361 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778361/778361 [==============================] - 3s 4us/step - loss: 0.1244 - acc: 0.9597 - val_loss: 0.1241 - val_acc: 0.9601\n",
      "Train on 779342 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779342/779342 [==============================] - 3s 4us/step - loss: 0.1257 - acc: 0.9593 - val_loss: 0.1240 - val_acc: 0.9601\n",
      "Train on 779340 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779340/779340 [==============================] - 3s 4us/step - loss: 0.1248 - acc: 0.9600 - val_loss: 0.1241 - val_acc: 0.9599\n",
      "Train on 778713 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778713/778713 [==============================] - 3s 4us/step - loss: 0.1249 - acc: 0.9599 - val_loss: 0.1246 - val_acc: 0.9599\n",
      "Train on 778681 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778681/778681 [==============================] - 3s 4us/step - loss: 0.1258 - acc: 0.9596 - val_loss: 0.1256 - val_acc: 0.9596\n",
      "Train on 779355 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779355/779355 [==============================] - 3s 4us/step - loss: 0.1253 - acc: 0.9597 - val_loss: 0.1236 - val_acc: 0.9603\n",
      "Train on 778929 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778929/778929 [==============================] - 3s 4us/step - loss: 0.1245 - acc: 0.9598 - val_loss: 0.1242 - val_acc: 0.9602\n",
      "Train on 778648 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778648/778648 [==============================] - 3s 4us/step - loss: 0.1265 - acc: 0.9593 - val_loss: 0.1262 - val_acc: 0.9595\n",
      "Train on 779376 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779376/779376 [==============================] - 3s 4us/step - loss: 0.1255 - acc: 0.9595 - val_loss: 0.1239 - val_acc: 0.9601\n",
      "Train on 779819 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779819/779819 [==============================] - 3s 4us/step - loss: 0.1250 - acc: 0.9599 - val_loss: 0.1235 - val_acc: 0.9602\n",
      "Train on 777823 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777823/777823 [==============================] - 3s 4us/step - loss: 0.1247 - acc: 0.9598 - val_loss: 0.1237 - val_acc: 0.9601\n",
      "Train on 779261 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779261/779261 [==============================] - 3s 4us/step - loss: 0.1244 - acc: 0.9599 - val_loss: 0.1235 - val_acc: 0.9603\n",
      "Train on 779044 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779044/779044 [==============================] - 3s 4us/step - loss: 0.1254 - acc: 0.9597 - val_loss: 0.1238 - val_acc: 0.9604\n",
      "Train on 779375 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779375/779375 [==============================] - 3s 4us/step - loss: 0.1249 - acc: 0.9597 - val_loss: 0.1235 - val_acc: 0.9604\n",
      "Train on 779426 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779426/779426 [==============================] - 3s 4us/step - loss: 0.1253 - acc: 0.9597 - val_loss: 0.1254 - val_acc: 0.9597\n",
      "Train on 778292 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778292/778292 [==============================] - 3s 4us/step - loss: 0.1248 - acc: 0.9597 - val_loss: 0.1263 - val_acc: 0.9592\n",
      "Train on 779406 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779406/779406 [==============================] - 3s 4us/step - loss: 0.1255 - acc: 0.9596 - val_loss: 0.1238 - val_acc: 0.9602\n",
      "Train on 779036 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779036/779036 [==============================] - 3s 4us/step - loss: 0.1250 - acc: 0.9597 - val_loss: 0.1253 - val_acc: 0.9597\n",
      "Train on 779137 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779137/779137 [==============================] - 3s 4us/step - loss: 0.1253 - acc: 0.9595 - val_loss: 0.1242 - val_acc: 0.9600\n",
      "Train on 778609 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778609/778609 [==============================] - 3s 4us/step - loss: 0.1246 - acc: 0.9597 - val_loss: 0.1242 - val_acc: 0.9602\n",
      "Train on 778375 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778375/778375 [==============================] - 3s 4us/step - loss: 0.1253 - acc: 0.9596 - val_loss: 0.1256 - val_acc: 0.9597\n",
      "Train on 778727 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778727/778727 [==============================] - 3s 4us/step - loss: 0.1256 - acc: 0.9594 - val_loss: 0.1244 - val_acc: 0.9602\n",
      "Train on 778918 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778918/778918 [==============================] - 3s 4us/step - loss: 0.1240 - acc: 0.9600 - val_loss: 0.1241 - val_acc: 0.9599\n",
      "Train on 779901 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779901/779901 [==============================] - 3s 4us/step - loss: 0.1250 - acc: 0.9598 - val_loss: 0.1241 - val_acc: 0.9600\n",
      "Train on 779085 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779085/779085 [==============================] - 3s 4us/step - loss: 0.1247 - acc: 0.9599 - val_loss: 0.1243 - val_acc: 0.9603\n",
      "Train on 778656 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778656/778656 [==============================] - 3s 4us/step - loss: 0.1248 - acc: 0.9598 - val_loss: 0.1255 - val_acc: 0.9595\n",
      "Train on 779245 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779245/779245 [==============================] - 3s 4us/step - loss: 0.1255 - acc: 0.9597 - val_loss: 0.1235 - val_acc: 0.9600\n",
      "Train on 779200 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779200/779200 [==============================] - 3s 4us/step - loss: 0.1247 - acc: 0.9597 - val_loss: 0.1237 - val_acc: 0.9602\n",
      "Train on 778785 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778785/778785 [==============================] - 3s 4us/step - loss: 0.1249 - acc: 0.9596 - val_loss: 0.1246 - val_acc: 0.9598\n",
      "Train on 779256 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779256/779256 [==============================] - 3s 4us/step - loss: 0.1251 - acc: 0.9598 - val_loss: 0.1237 - val_acc: 0.9601\n",
      "Train on 778652 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778652/778652 [==============================] - 3s 4us/step - loss: 0.1242 - acc: 0.9599 - val_loss: 0.1273 - val_acc: 0.9591\n",
      "Train on 778928 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778928/778928 [==============================] - 3s 4us/step - loss: 0.1250 - acc: 0.9598 - val_loss: 0.1234 - val_acc: 0.9604\n",
      "Train on 779305 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779305/779305 [==============================] - 3s 4us/step - loss: 0.1248 - acc: 0.9600 - val_loss: 0.1248 - val_acc: 0.9598\n",
      "Train on 777755 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777755/777755 [==============================] - 3s 4us/step - loss: 0.1249 - acc: 0.9597 - val_loss: 0.1236 - val_acc: 0.9604\n",
      "Train on 778343 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778343/778343 [==============================] - 3s 4us/step - loss: 0.1247 - acc: 0.9598 - val_loss: 0.1253 - val_acc: 0.9595\n",
      "Train on 778508 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778508/778508 [==============================] - 3s 4us/step - loss: 0.1250 - acc: 0.9596 - val_loss: 0.1245 - val_acc: 0.9597\n",
      "Train on 779180 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779180/779180 [==============================] - 3s 4us/step - loss: 0.1255 - acc: 0.9594 - val_loss: 0.1245 - val_acc: 0.9599\n",
      "Train on 779381 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779381/779381 [==============================] - 3s 4us/step - loss: 0.1244 - acc: 0.9600 - val_loss: 0.1265 - val_acc: 0.9593\n",
      "Train on 779213 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779213/779213 [==============================] - 3s 4us/step - loss: 0.1260 - acc: 0.9594 - val_loss: 0.1242 - val_acc: 0.9601\n",
      "Train on 778785 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778785/778785 [==============================] - 3s 4us/step - loss: 0.1249 - acc: 0.9601 - val_loss: 0.1247 - val_acc: 0.9597\n",
      "Train on 779822 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779822/779822 [==============================] - 3s 4us/step - loss: 0.1245 - acc: 0.9599 - val_loss: 0.1242 - val_acc: 0.9600\n",
      "Train on 779478 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779478/779478 [==============================] - 3s 4us/step - loss: 0.1241 - acc: 0.9602 - val_loss: 0.1246 - val_acc: 0.9600\n",
      "Train on 779282 samples, validate on 193733 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "779282/779282 [==============================] - 3s 4us/step - loss: 0.1238 - acc: 0.9600 - val_loss: 0.1239 - val_acc: 0.9602\n",
      "Train on 778818 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778818/778818 [==============================] - 3s 4us/step - loss: 0.1247 - acc: 0.9598 - val_loss: 0.1253 - val_acc: 0.9597\n",
      "Train on 779524 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779524/779524 [==============================] - 3s 4us/step - loss: 0.1242 - acc: 0.9599 - val_loss: 0.1237 - val_acc: 0.9599\n",
      "Train on 779937 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779937/779937 [==============================] - 3s 4us/step - loss: 0.1244 - acc: 0.9599 - val_loss: 0.1239 - val_acc: 0.9601\n",
      "Train on 778703 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778703/778703 [==============================] - 3s 4us/step - loss: 0.1247 - acc: 0.9598 - val_loss: 0.1246 - val_acc: 0.9598\n",
      "Train on 779453 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779453/779453 [==============================] - 3s 4us/step - loss: 0.1244 - acc: 0.9598 - val_loss: 0.1248 - val_acc: 0.9599\n",
      "Train on 777930 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777930/777930 [==============================] - 3s 4us/step - loss: 0.1245 - acc: 0.9598 - val_loss: 0.1229 - val_acc: 0.9604\n",
      "Train on 779649 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779649/779649 [==============================] - 3s 4us/step - loss: 0.1243 - acc: 0.9600 - val_loss: 0.1229 - val_acc: 0.9604\n",
      "Train on 778951 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778951/778951 [==============================] - 3s 4us/step - loss: 0.1242 - acc: 0.9600 - val_loss: 0.1230 - val_acc: 0.9604\n",
      "Train on 778506 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778506/778506 [==============================] - 3s 4us/step - loss: 0.1243 - acc: 0.9599 - val_loss: 0.1238 - val_acc: 0.9602\n",
      "Train on 778297 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778297/778297 [==============================] - 3s 4us/step - loss: 0.1244 - acc: 0.9599 - val_loss: 0.1356 - val_acc: 0.9557\n",
      "Train on 779077 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779077/779077 [==============================] - 3s 4us/step - loss: 0.1263 - acc: 0.9593 - val_loss: 0.1231 - val_acc: 0.9603\n",
      "Train on 779156 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779156/779156 [==============================] - 4s 5us/step - loss: 0.1246 - acc: 0.9599 - val_loss: 0.1243 - val_acc: 0.9596\n",
      "Train on 779331 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779331/779331 [==============================] - 3s 4us/step - loss: 0.1242 - acc: 0.9600 - val_loss: 0.1234 - val_acc: 0.9604\n",
      "Train on 779261 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779261/779261 [==============================] - 3s 4us/step - loss: 0.1238 - acc: 0.9602 - val_loss: 0.1229 - val_acc: 0.9604\n",
      "Train on 779115 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779115/779115 [==============================] - 3s 4us/step - loss: 0.1245 - acc: 0.9599 - val_loss: 0.1231 - val_acc: 0.9603\n",
      "Train on 778269 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778269/778269 [==============================] - 3s 4us/step - loss: 0.1242 - acc: 0.9599 - val_loss: 0.1633 - val_acc: 0.9429\n",
      "Train on 778914 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778914/778914 [==============================] - 3s 4us/step - loss: 0.1310 - acc: 0.9576 - val_loss: 0.1236 - val_acc: 0.9603\n",
      "Train on 779815 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779815/779815 [==============================] - 3s 4us/step - loss: 0.1247 - acc: 0.9599 - val_loss: 0.1228 - val_acc: 0.9606\n",
      "Train on 779210 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779210/779210 [==============================] - 3s 4us/step - loss: 0.1241 - acc: 0.9601 - val_loss: 0.1236 - val_acc: 0.9600\n",
      "Train on 779626 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779626/779626 [==============================] - 3s 4us/step - loss: 0.1239 - acc: 0.9601 - val_loss: 0.1238 - val_acc: 0.9601\n",
      "Train on 778292 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778292/778292 [==============================] - 3s 4us/step - loss: 0.1239 - acc: 0.9602 - val_loss: 0.1346 - val_acc: 0.9560\n",
      "Train on 779204 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779204/779204 [==============================] - 3s 4us/step - loss: 0.1258 - acc: 0.9594 - val_loss: 0.1229 - val_acc: 0.9605\n",
      "Train on 778317 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778317/778317 [==============================] - 3s 4us/step - loss: 0.1241 - acc: 0.9601 - val_loss: 0.1251 - val_acc: 0.9594\n",
      "Train on 778491 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778491/778491 [==============================] - 3s 4us/step - loss: 0.1244 - acc: 0.9599 - val_loss: 0.1233 - val_acc: 0.9603\n",
      "Train on 779013 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779013/779013 [==============================] - 3s 4us/step - loss: 0.1240 - acc: 0.9599 - val_loss: 0.1236 - val_acc: 0.9602\n",
      "Train on 778662 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778662/778662 [==============================] - 3s 4us/step - loss: 0.1240 - acc: 0.9601 - val_loss: 0.1247 - val_acc: 0.9597\n",
      "Train on 778784 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778784/778784 [==============================] - 3s 4us/step - loss: 0.1244 - acc: 0.9599 - val_loss: 0.1233 - val_acc: 0.9602\n",
      "Train on 778122 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778122/778122 [==============================] - 3s 4us/step - loss: 0.1243 - acc: 0.9601 - val_loss: 0.1232 - val_acc: 0.9602\n",
      "Train on 779164 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779164/779164 [==============================] - 3s 4us/step - loss: 0.1236 - acc: 0.9601 - val_loss: 0.1230 - val_acc: 0.9605\n",
      "Train on 778819 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778819/778819 [==============================] - 3s 4us/step - loss: 0.1240 - acc: 0.9598 - val_loss: 0.1239 - val_acc: 0.9601\n",
      "Train on 778906 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778906/778906 [==============================] - 3s 4us/step - loss: 0.1244 - acc: 0.9598 - val_loss: 0.1234 - val_acc: 0.9603\n",
      "Train on 778260 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778260/778260 [==============================] - 3s 4us/step - loss: 0.1244 - acc: 0.9598 - val_loss: 0.1289 - val_acc: 0.9587\n",
      "Train on 779052 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779052/779052 [==============================] - 3s 4us/step - loss: 0.1260 - acc: 0.9595 - val_loss: 0.1246 - val_acc: 0.9599\n",
      "Train on 780016 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "780016/780016 [==============================] - 3s 4us/step - loss: 0.1238 - acc: 0.9601 - val_loss: 0.1231 - val_acc: 0.9605\n",
      "Train on 779028 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779028/779028 [==============================] - 3s 4us/step - loss: 0.1234 - acc: 0.9603 - val_loss: 0.1231 - val_acc: 0.9602\n",
      "Train on 778649 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778649/778649 [==============================] - 3s 4us/step - loss: 0.1241 - acc: 0.9601 - val_loss: 0.1235 - val_acc: 0.9602\n",
      "Train on 778891 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778891/778891 [==============================] - 3s 4us/step - loss: 0.1241 - acc: 0.9599 - val_loss: 0.1232 - val_acc: 0.9605\n",
      "Train on 778239 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778239/778239 [==============================] - 3s 4us/step - loss: 0.1239 - acc: 0.9599 - val_loss: 0.1236 - val_acc: 0.9602\n",
      "Train on 779361 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779361/779361 [==============================] - 3s 4us/step - loss: 0.1236 - acc: 0.9601 - val_loss: 0.1232 - val_acc: 0.9600\n",
      "Train on 779148 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779148/779148 [==============================] - 3s 4us/step - loss: 0.1237 - acc: 0.9602 - val_loss: 0.1227 - val_acc: 0.9606\n",
      "Train on 778556 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778556/778556 [==============================] - 3s 4us/step - loss: 0.1241 - acc: 0.9601 - val_loss: 0.1239 - val_acc: 0.9601\n",
      "Train on 778747 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778747/778747 [==============================] - 3s 4us/step - loss: 0.1244 - acc: 0.9599 - val_loss: 0.1252 - val_acc: 0.9595\n",
      "Train on 779071 samples, validate on 193733 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "779071/779071 [==============================] - 3s 4us/step - loss: 0.1242 - acc: 0.9600 - val_loss: 0.1238 - val_acc: 0.9602\n",
      "Train on 778910 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778910/778910 [==============================] - 3s 4us/step - loss: 0.1239 - acc: 0.9601 - val_loss: 0.1234 - val_acc: 0.9602\n",
      "Train on 778737 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778737/778737 [==============================] - 4s 5us/step - loss: 0.1239 - acc: 0.9601 - val_loss: 0.1229 - val_acc: 0.9603\n",
      "Train on 778840 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778840/778840 [==============================] - 3s 4us/step - loss: 0.1238 - acc: 0.9602 - val_loss: 0.1250 - val_acc: 0.9599\n",
      "Train on 779065 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779065/779065 [==============================] - 3s 4us/step - loss: 0.1236 - acc: 0.9601 - val_loss: 0.1228 - val_acc: 0.9604\n",
      "Train on 779116 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779116/779116 [==============================] - 3s 4us/step - loss: 0.1248 - acc: 0.9599 - val_loss: 0.1233 - val_acc: 0.9602\n",
      "Train on 779384 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779384/779384 [==============================] - 3s 4us/step - loss: 0.1234 - acc: 0.9601 - val_loss: 0.1238 - val_acc: 0.9600\n",
      "Train on 779132 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779132/779132 [==============================] - 3s 4us/step - loss: 0.1242 - acc: 0.9600 - val_loss: 0.1235 - val_acc: 0.9603\n",
      "Train on 780359 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "780359/780359 [==============================] - 3s 4us/step - loss: 0.1235 - acc: 0.9603 - val_loss: 0.1232 - val_acc: 0.9602\n",
      "Train on 778628 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778628/778628 [==============================] - 3s 4us/step - loss: 0.1240 - acc: 0.9600 - val_loss: 0.1253 - val_acc: 0.9596\n",
      "Train on 778867 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778867/778867 [==============================] - 3s 4us/step - loss: 0.1242 - acc: 0.9600 - val_loss: 0.1247 - val_acc: 0.9596\n",
      "Train on 779260 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779260/779260 [==============================] - 3s 4us/step - loss: 0.1239 - acc: 0.9600 - val_loss: 0.1227 - val_acc: 0.9605\n",
      "Train on 778781 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778781/778781 [==============================] - 3s 4us/step - loss: 0.1243 - acc: 0.9598 - val_loss: 0.1232 - val_acc: 0.9602\n",
      "Train on 779295 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779295/779295 [==============================] - 4s 5us/step - loss: 0.1237 - acc: 0.9603 - val_loss: 0.1230 - val_acc: 0.9602\n",
      "Train on 779779 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779779/779779 [==============================] - 4s 5us/step - loss: 0.1240 - acc: 0.9603 - val_loss: 0.1231 - val_acc: 0.9603\n",
      "Train on 779409 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779409/779409 [==============================] - 3s 4us/step - loss: 0.1241 - acc: 0.9602 - val_loss: 0.1230 - val_acc: 0.9602\n",
      "Train on 778593 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778593/778593 [==============================] - 3s 4us/step - loss: 0.1245 - acc: 0.9599 - val_loss: 0.1237 - val_acc: 0.9603\n",
      "Train on 779462 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779462/779462 [==============================] - 4s 5us/step - loss: 0.1242 - acc: 0.9600 - val_loss: 0.1242 - val_acc: 0.9601\n",
      "Train on 777720 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777720/777720 [==============================] - 3s 4us/step - loss: 0.1256 - acc: 0.9596 - val_loss: 0.1240 - val_acc: 0.9599\n",
      "Train on 779600 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779600/779600 [==============================] - 3s 4us/step - loss: 0.1243 - acc: 0.9600 - val_loss: 0.1237 - val_acc: 0.9602\n",
      "Train on 778356 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778356/778356 [==============================] - 3s 4us/step - loss: 0.1243 - acc: 0.9600 - val_loss: 0.1239 - val_acc: 0.9601\n",
      "Train on 778660 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778660/778660 [==============================] - 3s 4us/step - loss: 0.1243 - acc: 0.9601 - val_loss: 0.1248 - val_acc: 0.9597\n",
      "Train on 779324 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779324/779324 [==============================] - 3s 4us/step - loss: 0.1240 - acc: 0.9602 - val_loss: 0.1227 - val_acc: 0.9604\n",
      "Train on 779369 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779369/779369 [==============================] - 3s 4us/step - loss: 0.1235 - acc: 0.9602 - val_loss: 0.1229 - val_acc: 0.9605\n",
      "Train on 778977 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778977/778977 [==============================] - 3s 4us/step - loss: 0.1240 - acc: 0.9601 - val_loss: 0.1235 - val_acc: 0.9600\n",
      "Train on 779108 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779108/779108 [==============================] - 3s 4us/step - loss: 0.1243 - acc: 0.9602 - val_loss: 0.1230 - val_acc: 0.9605\n",
      "Train on 778286 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778286/778286 [==============================] - 3s 4us/step - loss: 0.1238 - acc: 0.9600 - val_loss: 0.1258 - val_acc: 0.9594\n",
      "Train on 778838 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778838/778838 [==============================] - 3s 4us/step - loss: 0.1238 - acc: 0.9600 - val_loss: 0.1250 - val_acc: 0.9596\n",
      "Train on 779170 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779170/779170 [==============================] - 3s 4us/step - loss: 0.1238 - acc: 0.9601 - val_loss: 0.1226 - val_acc: 0.9605\n",
      "Train on 778429 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778429/778429 [==============================] - 3s 4us/step - loss: 0.1238 - acc: 0.9602 - val_loss: 0.1241 - val_acc: 0.9597\n",
      "Train on 778663 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778663/778663 [==============================] - 3s 4us/step - loss: 0.1237 - acc: 0.9602 - val_loss: 0.1233 - val_acc: 0.9604\n",
      "Train on 778139 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778139/778139 [==============================] - 3s 4us/step - loss: 0.1239 - acc: 0.9600 - val_loss: 0.1229 - val_acc: 0.9603\n",
      "Train on 779408 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779408/779408 [==============================] - 3s 4us/step - loss: 0.1244 - acc: 0.9599 - val_loss: 0.1234 - val_acc: 0.9602\n",
      "Train on 780245 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "780245/780245 [==============================] - 3s 4us/step - loss: 0.1243 - acc: 0.9600 - val_loss: 0.1231 - val_acc: 0.9604\n",
      "Train on 779353 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779353/779353 [==============================] - 3s 4us/step - loss: 0.1234 - acc: 0.9602 - val_loss: 0.1227 - val_acc: 0.9604\n",
      "Train on 778645 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778645/778645 [==============================] - 3s 4us/step - loss: 0.1243 - acc: 0.9599 - val_loss: 0.1232 - val_acc: 0.9602\n",
      "Train on 778310 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778310/778310 [==============================] - 3s 4us/step - loss: 0.1233 - acc: 0.9602 - val_loss: 0.1364 - val_acc: 0.9568\n",
      "Train on 779596 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779596/779596 [==============================] - 3s 4us/step - loss: 0.1255 - acc: 0.9596 - val_loss: 0.1231 - val_acc: 0.9603\n",
      "Train on 779018 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779018/779018 [==============================] - 3s 4us/step - loss: 0.1238 - acc: 0.9602 - val_loss: 0.1228 - val_acc: 0.9603\n",
      "Train on 779091 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779091/779091 [==============================] - 3s 4us/step - loss: 0.1233 - acc: 0.9603 - val_loss: 0.1245 - val_acc: 0.9599\n",
      "Train on 779086 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779086/779086 [==============================] - 3s 4us/step - loss: 0.1240 - acc: 0.9600 - val_loss: 0.1230 - val_acc: 0.9602\n",
      "Train on 778218 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778218/778218 [==============================] - 3s 4us/step - loss: 0.1238 - acc: 0.9603 - val_loss: 0.1224 - val_acc: 0.9605\n",
      "Train on 779197 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779197/779197 [==============================] - 3s 4us/step - loss: 0.1230 - acc: 0.9604 - val_loss: 0.1226 - val_acc: 0.9605\n",
      "Train on 779251 samples, validate on 193733 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "779251/779251 [==============================] - 3s 4us/step - loss: 0.1241 - acc: 0.9601 - val_loss: 0.1230 - val_acc: 0.9603\n",
      "Train on 779179 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779179/779179 [==============================] - 3s 4us/step - loss: 0.1232 - acc: 0.9605 - val_loss: 0.1235 - val_acc: 0.9601\n",
      "Train on 778029 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778029/778029 [==============================] - 3s 4us/step - loss: 0.1236 - acc: 0.9602 - val_loss: 0.1226 - val_acc: 0.9604\n",
      "Train on 778437 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778437/778437 [==============================] - 3s 4us/step - loss: 0.1234 - acc: 0.9601 - val_loss: 0.1249 - val_acc: 0.9597\n",
      "Train on 778648 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778648/778648 [==============================] - 3s 4us/step - loss: 0.1245 - acc: 0.9599 - val_loss: 0.1229 - val_acc: 0.9604\n",
      "Train on 778623 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778623/778623 [==============================] - 3s 4us/step - loss: 0.1239 - acc: 0.9601 - val_loss: 0.1231 - val_acc: 0.9603\n",
      "Train on 779464 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779464/779464 [==============================] - 3s 4us/step - loss: 0.1240 - acc: 0.9602 - val_loss: 0.1221 - val_acc: 0.9607\n",
      "Train on 778625 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778625/778625 [==============================] - 4s 5us/step - loss: 0.1236 - acc: 0.9601 - val_loss: 0.1277 - val_acc: 0.9590\n",
      "Train on 778597 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778597/778597 [==============================] - 3s 4us/step - loss: 0.1296 - acc: 0.9581 - val_loss: 0.1284 - val_acc: 0.9586\n",
      "Train on 778842 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778842/778842 [==============================] - 3s 4us/step - loss: 0.1261 - acc: 0.9592 - val_loss: 0.1239 - val_acc: 0.9600\n",
      "Train on 779252 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779252/779252 [==============================] - 3s 4us/step - loss: 0.1244 - acc: 0.9598 - val_loss: 0.1238 - val_acc: 0.9603\n",
      "Train on 779644 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779644/779644 [==============================] - 3s 4us/step - loss: 0.1245 - acc: 0.9600 - val_loss: 0.1242 - val_acc: 0.9600\n",
      "Train on 779722 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779722/779722 [==============================] - 3s 4us/step - loss: 0.1238 - acc: 0.9599 - val_loss: 0.1225 - val_acc: 0.9605\n",
      "Train on 778327 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778327/778327 [==============================] - 3s 4us/step - loss: 0.1229 - acc: 0.9604 - val_loss: 0.1229 - val_acc: 0.9604\n",
      "Train on 779352 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779352/779352 [==============================] - 3s 4us/step - loss: 0.1239 - acc: 0.9602 - val_loss: 0.1235 - val_acc: 0.9602\n",
      "Train on 778597 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778597/778597 [==============================] - 3s 4us/step - loss: 0.1238 - acc: 0.9601 - val_loss: 0.1242 - val_acc: 0.9600\n",
      "Train on 778652 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778652/778652 [==============================] - 3s 4us/step - loss: 0.1237 - acc: 0.9604 - val_loss: 0.1238 - val_acc: 0.9602\n",
      "Train on 780459 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "780459/780459 [==============================] - 3s 4us/step - loss: 0.1244 - acc: 0.9600 - val_loss: 0.1239 - val_acc: 0.9601\n",
      "Train on 778518 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778518/778518 [==============================] - 3s 4us/step - loss: 0.1236 - acc: 0.9604 - val_loss: 0.1227 - val_acc: 0.9605\n",
      "Train on 779228 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779228/779228 [==============================] - 3s 4us/step - loss: 0.1234 - acc: 0.9603 - val_loss: 0.1220 - val_acc: 0.9606\n",
      "Train on 778828 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778828/778828 [==============================] - 3s 4us/step - loss: 0.1235 - acc: 0.9602 - val_loss: 0.1233 - val_acc: 0.9603\n",
      "Train on 779745 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779745/779745 [==============================] - 3s 4us/step - loss: 0.1234 - acc: 0.9601 - val_loss: 0.1228 - val_acc: 0.9605\n",
      "Train on 778562 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778562/778562 [==============================] - 3s 4us/step - loss: 0.1236 - acc: 0.9602 - val_loss: 0.1226 - val_acc: 0.9606\n",
      "Train on 779667 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779667/779667 [==============================] - 3s 4us/step - loss: 0.1236 - acc: 0.9605 - val_loss: 0.1228 - val_acc: 0.9602\n",
      "Train on 778899 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778899/778899 [==============================] - 4s 5us/step - loss: 0.1234 - acc: 0.9601 - val_loss: 0.1245 - val_acc: 0.9595\n",
      "Train on 779222 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779222/779222 [==============================] - 3s 4us/step - loss: 0.1238 - acc: 0.9602 - val_loss: 0.1237 - val_acc: 0.9602\n",
      "Train on 779027 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779027/779027 [==============================] - 3s 4us/step - loss: 0.1238 - acc: 0.9601 - val_loss: 0.1229 - val_acc: 0.9605\n",
      "Train on 779088 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779088/779088 [==============================] - 3s 4us/step - loss: 0.1235 - acc: 0.9602 - val_loss: 0.1240 - val_acc: 0.9601\n",
      "Train on 778871 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778871/778871 [==============================] - 3s 4us/step - loss: 0.1235 - acc: 0.9602 - val_loss: 0.1229 - val_acc: 0.9603\n",
      "Train on 779712 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779712/779712 [==============================] - 3s 4us/step - loss: 0.1234 - acc: 0.9602 - val_loss: 0.1237 - val_acc: 0.9598\n",
      "Train on 779218 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779218/779218 [==============================] - 3s 4us/step - loss: 0.1228 - acc: 0.9605 - val_loss: 0.1232 - val_acc: 0.9603\n",
      "Train on 778476 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778476/778476 [==============================] - 3s 4us/step - loss: 0.1233 - acc: 0.9603 - val_loss: 0.1246 - val_acc: 0.9597\n",
      "Train on 779103 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779103/779103 [==============================] - 3s 4us/step - loss: 0.1235 - acc: 0.9603 - val_loss: 0.1239 - val_acc: 0.9600\n",
      "Train on 779286 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779286/779286 [==============================] - 3s 4us/step - loss: 0.1240 - acc: 0.9602 - val_loss: 0.1228 - val_acc: 0.9606\n",
      "Train on 779285 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779285/779285 [==============================] - 3s 4us/step - loss: 0.1233 - acc: 0.9604 - val_loss: 0.1233 - val_acc: 0.9604\n",
      "Train on 778769 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778769/778769 [==============================] - 3s 4us/step - loss: 0.1228 - acc: 0.9605 - val_loss: 0.1232 - val_acc: 0.9604\n",
      "Train on 778897 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778897/778897 [==============================] - 3s 4us/step - loss: 0.1230 - acc: 0.9604 - val_loss: 0.1231 - val_acc: 0.9602\n",
      "Train on 779054 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779054/779054 [==============================] - 3s 4us/step - loss: 0.1236 - acc: 0.9603 - val_loss: 0.1224 - val_acc: 0.9605\n",
      "Train on 780466 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "780466/780466 [==============================] - 3s 4us/step - loss: 0.1227 - acc: 0.9606 - val_loss: 0.1222 - val_acc: 0.9607\n",
      "Train on 779280 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779280/779280 [==============================] - 3s 4us/step - loss: 0.1232 - acc: 0.9602 - val_loss: 0.1219 - val_acc: 0.9608\n",
      "Train on 779573 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779573/779573 [==============================] - 3s 4us/step - loss: 0.1228 - acc: 0.9605 - val_loss: 0.1231 - val_acc: 0.9605\n",
      "Train on 779630 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779630/779630 [==============================] - 3s 4us/step - loss: 0.1230 - acc: 0.9603 - val_loss: 0.1224 - val_acc: 0.9605\n",
      "Train on 778595 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778595/778595 [==============================] - 3s 4us/step - loss: 0.1229 - acc: 0.9605 - val_loss: 0.1237 - val_acc: 0.9603\n",
      "Train on 779528 samples, validate on 193733 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "779528/779528 [==============================] - 3s 4us/step - loss: 0.1236 - acc: 0.9603 - val_loss: 0.1235 - val_acc: 0.9604\n",
      "Train on 778448 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778448/778448 [==============================] - 3s 4us/step - loss: 0.1233 - acc: 0.9603 - val_loss: 0.1235 - val_acc: 0.9602\n",
      "Train on 778688 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778688/778688 [==============================] - 3s 4us/step - loss: 0.1233 - acc: 0.9603 - val_loss: 0.1232 - val_acc: 0.9603\n",
      "Train on 778055 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778055/778055 [==============================] - 3s 4us/step - loss: 0.1228 - acc: 0.9606 - val_loss: 0.1230 - val_acc: 0.9604\n",
      "Train on 778492 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778492/778492 [==============================] - 3s 4us/step - loss: 0.1237 - acc: 0.9602 - val_loss: 0.1239 - val_acc: 0.9600\n",
      "Train on 779187 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779187/779187 [==============================] - 3s 4us/step - loss: 0.1235 - acc: 0.9602 - val_loss: 0.1232 - val_acc: 0.9602\n",
      "Train on 778513 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778513/778513 [==============================] - 3s 4us/step - loss: 0.1229 - acc: 0.9605 - val_loss: 0.1225 - val_acc: 0.9605\n",
      "Train on 779756 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779756/779756 [==============================] - 3s 4us/step - loss: 0.1237 - acc: 0.9601 - val_loss: 0.1221 - val_acc: 0.9607\n",
      "Train on 778900 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778900/778900 [==============================] - 3s 4us/step - loss: 0.1229 - acc: 0.9603 - val_loss: 0.1232 - val_acc: 0.9605\n",
      "Train on 779342 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779342/779342 [==============================] - 3s 4us/step - loss: 0.1231 - acc: 0.9603 - val_loss: 0.1236 - val_acc: 0.9601\n",
      "Train on 779260 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779260/779260 [==============================] - 3s 4us/step - loss: 0.1233 - acc: 0.9604 - val_loss: 0.1227 - val_acc: 0.9605\n",
      "Train on 778504 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778504/778504 [==============================] - 3s 4us/step - loss: 0.1228 - acc: 0.9605 - val_loss: 0.1238 - val_acc: 0.9603\n",
      "Train on 778154 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778154/778154 [==============================] - 3s 4us/step - loss: 0.1244 - acc: 0.9602 - val_loss: 0.1226 - val_acc: 0.9607\n",
      "Train on 779272 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779272/779272 [==============================] - 3s 4us/step - loss: 0.1228 - acc: 0.9605 - val_loss: 0.1232 - val_acc: 0.9602\n",
      "Train on 778406 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778406/778406 [==============================] - 3s 4us/step - loss: 0.1229 - acc: 0.9602 - val_loss: 0.1235 - val_acc: 0.9600\n",
      "Train on 779616 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779616/779616 [==============================] - 3s 4us/step - loss: 0.1233 - acc: 0.9602 - val_loss: 0.1227 - val_acc: 0.9603\n",
      "Train on 779657 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779657/779657 [==============================] - 3s 4us/step - loss: 0.1229 - acc: 0.9604 - val_loss: 0.1223 - val_acc: 0.9609\n",
      "Train on 779546 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779546/779546 [==============================] - 3s 4us/step - loss: 0.1235 - acc: 0.9602 - val_loss: 0.1223 - val_acc: 0.9608\n",
      "Train on 779287 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779287/779287 [==============================] - 3s 4us/step - loss: 0.1231 - acc: 0.9602 - val_loss: 0.1225 - val_acc: 0.9604\n",
      "Train on 779246 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779246/779246 [==============================] - 3s 4us/step - loss: 0.1223 - acc: 0.9606 - val_loss: 0.1223 - val_acc: 0.9607\n",
      "Train on 779052 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779052/779052 [==============================] - 3s 4us/step - loss: 0.1227 - acc: 0.9604 - val_loss: 0.1229 - val_acc: 0.9606\n",
      "Train on 778966 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778966/778966 [==============================] - 3s 4us/step - loss: 0.1229 - acc: 0.9605 - val_loss: 0.1223 - val_acc: 0.9607\n",
      "Train on 779152 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779152/779152 [==============================] - 3s 4us/step - loss: 0.1230 - acc: 0.9604 - val_loss: 0.1241 - val_acc: 0.9601\n",
      "Train on 778776 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778776/778776 [==============================] - 3s 4us/step - loss: 0.1228 - acc: 0.9604 - val_loss: 0.1224 - val_acc: 0.9605\n",
      "Train on 779385 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779385/779385 [==============================] - 3s 4us/step - loss: 0.1232 - acc: 0.9603 - val_loss: 0.1227 - val_acc: 0.9603\n",
      "Train on 779486 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779486/779486 [==============================] - 3s 4us/step - loss: 0.1227 - acc: 0.9605 - val_loss: 0.1232 - val_acc: 0.9605\n",
      "Train on 778724 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778724/778724 [==============================] - 3s 4us/step - loss: 0.1229 - acc: 0.9604 - val_loss: 0.1231 - val_acc: 0.9602\n",
      "Train on 779754 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779754/779754 [==============================] - 3s 4us/step - loss: 0.1227 - acc: 0.9604 - val_loss: 0.1231 - val_acc: 0.9604\n",
      "Train on 780325 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "780325/780325 [==============================] - 3s 4us/step - loss: 0.1230 - acc: 0.9604 - val_loss: 0.1221 - val_acc: 0.9607\n",
      "Train on 778972 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778972/778972 [==============================] - 3s 4us/step - loss: 0.1231 - acc: 0.9605 - val_loss: 0.1249 - val_acc: 0.9596\n",
      "Train on 779733 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779733/779733 [==============================] - 3s 4us/step - loss: 0.1231 - acc: 0.9603 - val_loss: 0.1231 - val_acc: 0.9603\n",
      "Train on 779551 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779551/779551 [==============================] - 3s 4us/step - loss: 0.1226 - acc: 0.9602 - val_loss: 0.1227 - val_acc: 0.9603\n",
      "Train on 778243 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778243/778243 [==============================] - 3s 4us/step - loss: 0.1235 - acc: 0.9602 - val_loss: 0.1255 - val_acc: 0.9599\n",
      "Train on 779552 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779552/779552 [==============================] - 3s 4us/step - loss: 0.1231 - acc: 0.9603 - val_loss: 0.1221 - val_acc: 0.9607\n",
      "Train on 778419 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778419/778419 [==============================] - 3s 4us/step - loss: 0.1226 - acc: 0.9605 - val_loss: 0.1222 - val_acc: 0.9606\n",
      "Train on 778581 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778581/778581 [==============================] - 3s 4us/step - loss: 0.1223 - acc: 0.9606 - val_loss: 0.1222 - val_acc: 0.9607\n",
      "Train on 778775 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778775/778775 [==============================] - 3s 4us/step - loss: 0.1231 - acc: 0.9603 - val_loss: 0.1241 - val_acc: 0.9601\n",
      "Train on 779329 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779329/779329 [==============================] - 3s 4us/step - loss: 0.1227 - acc: 0.9605 - val_loss: 0.1220 - val_acc: 0.9606\n",
      "Train on 779067 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779067/779067 [==============================] - 3s 4us/step - loss: 0.1230 - acc: 0.9604 - val_loss: 0.1238 - val_acc: 0.9601\n",
      "Train on 779040 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779040/779040 [==============================] - 3s 4us/step - loss: 0.1235 - acc: 0.9603 - val_loss: 0.1228 - val_acc: 0.9604\n",
      "Train on 779216 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779216/779216 [==============================] - 3s 4us/step - loss: 0.1225 - acc: 0.9604 - val_loss: 0.1222 - val_acc: 0.9607\n",
      "Train on 778679 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778679/778679 [==============================] - 3s 4us/step - loss: 0.1228 - acc: 0.9604 - val_loss: 0.1240 - val_acc: 0.9600\n",
      "Train on 779038 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779038/779038 [==============================] - 3s 4us/step - loss: 0.1237 - acc: 0.9603 - val_loss: 0.1225 - val_acc: 0.9606\n",
      "Train on 778427 samples, validate on 193733 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778427/778427 [==============================] - 3s 4us/step - loss: 0.1230 - acc: 0.9604 - val_loss: 0.1232 - val_acc: 0.9603\n",
      "Train on 780769 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "780769/780769 [==============================] - 3s 4us/step - loss: 0.1230 - acc: 0.9604 - val_loss: 0.1218 - val_acc: 0.9607\n",
      "Train on 779005 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779005/779005 [==============================] - 3s 4us/step - loss: 0.1226 - acc: 0.9606 - val_loss: 0.1229 - val_acc: 0.9605\n",
      "Train on 779618 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779618/779618 [==============================] - 3s 4us/step - loss: 0.1227 - acc: 0.9606 - val_loss: 0.1228 - val_acc: 0.9605\n",
      "Train on 779024 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779024/779024 [==============================] - 3s 4us/step - loss: 0.1229 - acc: 0.9605 - val_loss: 0.1220 - val_acc: 0.9609\n",
      "Train on 779193 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779193/779193 [==============================] - 3s 4us/step - loss: 0.1233 - acc: 0.9604 - val_loss: 0.1221 - val_acc: 0.9607\n",
      "Train on 778167 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778167/778167 [==============================] - 3s 4us/step - loss: 0.1231 - acc: 0.9603 - val_loss: 0.1230 - val_acc: 0.9603\n",
      "Train on 779596 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779596/779596 [==============================] - 3s 4us/step - loss: 0.1230 - acc: 0.9605 - val_loss: 0.1227 - val_acc: 0.9605\n",
      "Train on 778925 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778925/778925 [==============================] - 3s 4us/step - loss: 0.1228 - acc: 0.9604 - val_loss: 0.1225 - val_acc: 0.9607\n",
      "Train on 779037 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779037/779037 [==============================] - 3s 4us/step - loss: 0.1233 - acc: 0.9603 - val_loss: 0.1231 - val_acc: 0.9605\n",
      "Train on 778572 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778572/778572 [==============================] - 3s 4us/step - loss: 0.1234 - acc: 0.9604 - val_loss: 0.1216 - val_acc: 0.9608\n",
      "Train on 777681 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777681/777681 [==============================] - 3s 4us/step - loss: 0.1226 - acc: 0.9604 - val_loss: 0.1222 - val_acc: 0.9607\n",
      "Train on 778980 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778980/778980 [==============================] - 3s 4us/step - loss: 0.1224 - acc: 0.9606 - val_loss: 0.1218 - val_acc: 0.9609\n",
      "Train on 778787 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778787/778787 [==============================] - 3s 4us/step - loss: 0.1229 - acc: 0.9604 - val_loss: 0.1226 - val_acc: 0.9603\n",
      "Train on 779288 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779288/779288 [==============================] - 3s 4us/step - loss: 0.1225 - acc: 0.9607 - val_loss: 0.1230 - val_acc: 0.9605\n",
      "Train on 778540 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778540/778540 [==============================] - 3s 4us/step - loss: 0.1229 - acc: 0.9603 - val_loss: 0.1245 - val_acc: 0.9597\n",
      "Train on 778781 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778781/778781 [==============================] - 3s 4us/step - loss: 0.1234 - acc: 0.9602 - val_loss: 0.1235 - val_acc: 0.9602\n",
      "Train on 779321 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779321/779321 [==============================] - 3s 4us/step - loss: 0.1228 - acc: 0.9605 - val_loss: 0.1249 - val_acc: 0.9594\n",
      "Train on 779641 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779641/779641 [==============================] - 3s 4us/step - loss: 0.1227 - acc: 0.9606 - val_loss: 0.1219 - val_acc: 0.9607\n",
      "Train on 778004 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778004/778004 [==============================] - 2s 3us/step - loss: 0.1229 - acc: 0.9604 - val_loss: 0.1218 - val_acc: 0.9608\n",
      "Train on 780339 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "780339/780339 [==============================] - 2s 2us/step - loss: 0.1232 - acc: 0.9603 - val_loss: 0.1228 - val_acc: 0.9607\n",
      "Train on 778732 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778732/778732 [==============================] - 2s 2us/step - loss: 0.1226 - acc: 0.9604 - val_loss: 0.1223 - val_acc: 0.9608\n",
      "Train on 779254 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779254/779254 [==============================] - 2s 2us/step - loss: 0.1233 - acc: 0.9603 - val_loss: 0.1224 - val_acc: 0.9607\n",
      "Train on 778949 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778949/778949 [==============================] - 2s 2us/step - loss: 0.1224 - acc: 0.9607 - val_loss: 0.1218 - val_acc: 0.9610\n",
      "Train on 778910 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778910/778910 [==============================] - 2s 2us/step - loss: 0.1233 - acc: 0.9604 - val_loss: 0.1219 - val_acc: 0.9608\n",
      "Train on 778982 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778982/778982 [==============================] - 2s 2us/step - loss: 0.1226 - acc: 0.9605 - val_loss: 0.1215 - val_acc: 0.9609\n",
      "Train on 779273 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779273/779273 [==============================] - 2s 2us/step - loss: 0.1230 - acc: 0.9604 - val_loss: 0.1223 - val_acc: 0.9606\n",
      "Train on 778917 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778917/778917 [==============================] - 2s 2us/step - loss: 0.1226 - acc: 0.9606 - val_loss: 0.1225 - val_acc: 0.9605\n",
      "Train on 778848 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778848/778848 [==============================] - 2s 2us/step - loss: 0.1223 - acc: 0.9606 - val_loss: 0.1232 - val_acc: 0.9603\n",
      "Train on 779825 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779825/779825 [==============================] - 2s 2us/step - loss: 0.1234 - acc: 0.9603 - val_loss: 0.1220 - val_acc: 0.9609\n",
      "Train on 779551 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779551/779551 [==============================] - 2s 2us/step - loss: 0.1221 - acc: 0.9607 - val_loss: 0.1222 - val_acc: 0.9607\n",
      "Train on 777956 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777956/777956 [==============================] - 2s 2us/step - loss: 0.1229 - acc: 0.9607 - val_loss: 0.1218 - val_acc: 0.9607\n",
      "Train on 779200 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779200/779200 [==============================] - 2s 2us/step - loss: 0.1231 - acc: 0.9603 - val_loss: 0.1233 - val_acc: 0.9602\n",
      "Train on 778568 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778568/778568 [==============================] - 2s 2us/step - loss: 0.1228 - acc: 0.9605 - val_loss: 0.1227 - val_acc: 0.9602\n",
      "Train on 778916 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778916/778916 [==============================] - 2s 2us/step - loss: 0.1227 - acc: 0.9604 - val_loss: 0.1222 - val_acc: 0.9608\n",
      "Train on 779616 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779616/779616 [==============================] - 2s 2us/step - loss: 0.1221 - acc: 0.9607 - val_loss: 0.1231 - val_acc: 0.9606\n",
      "Train on 778834 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778834/778834 [==============================] - 2s 2us/step - loss: 0.1229 - acc: 0.9605 - val_loss: 0.1239 - val_acc: 0.9599\n",
      "Train on 778443 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778443/778443 [==============================] - 2s 2us/step - loss: 0.1225 - acc: 0.9605 - val_loss: 0.1218 - val_acc: 0.9608\n",
      "Train on 778603 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778603/778603 [==============================] - 2s 2us/step - loss: 0.1240 - acc: 0.9601 - val_loss: 0.1224 - val_acc: 0.9606\n",
      "Train on 778824 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778824/778824 [==============================] - 2s 2us/step - loss: 0.1227 - acc: 0.9605 - val_loss: 0.1231 - val_acc: 0.9603\n",
      "Train on 779004 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779004/779004 [==============================] - 2s 2us/step - loss: 0.1228 - acc: 0.9605 - val_loss: 0.1231 - val_acc: 0.9603\n",
      "Train on 779411 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779411/779411 [==============================] - 2s 2us/step - loss: 0.1232 - acc: 0.9605 - val_loss: 0.1226 - val_acc: 0.9606\n",
      "Train on 778567 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778567/778567 [==============================] - 2s 2us/step - loss: 0.1225 - acc: 0.9605 - val_loss: 0.1234 - val_acc: 0.9601\n",
      "Train on 778884 samples, validate on 193733 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778884/778884 [==============================] - 2s 2us/step - loss: 0.1225 - acc: 0.9606 - val_loss: 0.1221 - val_acc: 0.9609\n",
      "Train on 778352 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778352/778352 [==============================] - 2s 2us/step - loss: 0.1227 - acc: 0.9606 - val_loss: 0.1266 - val_acc: 0.9592\n",
      "Train on 778640 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778640/778640 [==============================] - 2s 2us/step - loss: 0.1231 - acc: 0.9602 - val_loss: 0.1232 - val_acc: 0.9606\n",
      "Train on 779115 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779115/779115 [==============================] - 2s 2us/step - loss: 0.1225 - acc: 0.9606 - val_loss: 0.1224 - val_acc: 0.9605\n",
      "Train on 777641 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777641/777641 [==============================] - 2s 2us/step - loss: 0.1223 - acc: 0.9608 - val_loss: 0.1218 - val_acc: 0.9609\n",
      "Train on 779000 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779000/779000 [==============================] - 2s 2us/step - loss: 0.1217 - acc: 0.9609 - val_loss: 0.1215 - val_acc: 0.9608\n",
      "Train on 779742 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779742/779742 [==============================] - 2s 2us/step - loss: 0.1220 - acc: 0.9608 - val_loss: 0.1238 - val_acc: 0.9603\n",
      "Train on 778950 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778950/778950 [==============================] - 2s 2us/step - loss: 0.1233 - acc: 0.9603 - val_loss: 0.1238 - val_acc: 0.9602\n",
      "Train on 778228 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778228/778228 [==============================] - 2s 2us/step - loss: 0.1233 - acc: 0.9605 - val_loss: 0.1218 - val_acc: 0.9607\n",
      "Train on 779141 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779141/779141 [==============================] - 2s 2us/step - loss: 0.1222 - acc: 0.9607 - val_loss: 0.1218 - val_acc: 0.9608\n",
      "Train on 778041 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778041/778041 [==============================] - 2s 2us/step - loss: 0.1225 - acc: 0.9605 - val_loss: 0.1218 - val_acc: 0.9608\n",
      "Train on 778932 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778932/778932 [==============================] - 2s 2us/step - loss: 0.1220 - acc: 0.9609 - val_loss: 0.1223 - val_acc: 0.9605\n",
      "Train on 777966 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777966/777966 [==============================] - 2s 2us/step - loss: 0.1227 - acc: 0.9606 - val_loss: 0.1216 - val_acc: 0.9610\n",
      "Train on 779378 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779378/779378 [==============================] - 2s 2us/step - loss: 0.1228 - acc: 0.9605 - val_loss: 0.1227 - val_acc: 0.9606\n",
      "Train on 779047 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779047/779047 [==============================] - 2s 2us/step - loss: 0.1226 - acc: 0.9604 - val_loss: 0.1242 - val_acc: 0.9602\n",
      "Train on 778422 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778422/778422 [==============================] - 2s 2us/step - loss: 0.1232 - acc: 0.9604 - val_loss: 0.1223 - val_acc: 0.9605\n",
      "Train on 778017 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778017/778017 [==============================] - 2s 2us/step - loss: 0.1224 - acc: 0.9607 - val_loss: 0.1222 - val_acc: 0.9606\n",
      "Train on 778531 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778531/778531 [==============================] - 2s 2us/step - loss: 0.1229 - acc: 0.9605 - val_loss: 0.1222 - val_acc: 0.9605\n",
      "Train on 778484 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778484/778484 [==============================] - 2s 2us/step - loss: 0.1230 - acc: 0.9604 - val_loss: 0.1230 - val_acc: 0.9605\n",
      "Train on 778997 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778997/778997 [==============================] - 2s 2us/step - loss: 0.1224 - acc: 0.9608 - val_loss: 0.1226 - val_acc: 0.9602\n",
      "Train on 778603 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778603/778603 [==============================] - 2s 2us/step - loss: 0.1216 - acc: 0.9609 - val_loss: 0.1220 - val_acc: 0.9608\n",
      "Train on 778578 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778578/778578 [==============================] - 2s 2us/step - loss: 0.1226 - acc: 0.9607 - val_loss: 0.1224 - val_acc: 0.9605\n",
      "Train on 779731 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779731/779731 [==============================] - 2s 2us/step - loss: 0.1225 - acc: 0.9605 - val_loss: 0.1217 - val_acc: 0.9607\n",
      "Train on 778816 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778816/778816 [==============================] - 2s 2us/step - loss: 0.1221 - acc: 0.9608 - val_loss: 0.1225 - val_acc: 0.9604\n",
      "Train on 778342 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778342/778342 [==============================] - 2s 2us/step - loss: 0.1220 - acc: 0.9607 - val_loss: 0.1226 - val_acc: 0.9606\n",
      "Train on 779110 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779110/779110 [==============================] - 2s 2us/step - loss: 0.1234 - acc: 0.9603 - val_loss: 0.1223 - val_acc: 0.9605\n",
      "Train on 778605 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778605/778605 [==============================] - 2s 2us/step - loss: 0.1228 - acc: 0.9603 - val_loss: 0.1219 - val_acc: 0.9607\n",
      "Train on 779561 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779561/779561 [==============================] - 2s 2us/step - loss: 0.1219 - acc: 0.9608 - val_loss: 0.1244 - val_acc: 0.9599\n",
      "Train on 779058 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779058/779058 [==============================] - 2s 2us/step - loss: 0.1223 - acc: 0.9606 - val_loss: 0.1219 - val_acc: 0.9608\n",
      "Train on 779404 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779404/779404 [==============================] - 2s 2us/step - loss: 0.1228 - acc: 0.9606 - val_loss: 0.1218 - val_acc: 0.9609\n",
      "Train on 779355 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779355/779355 [==============================] - 2s 2us/step - loss: 0.1219 - acc: 0.9609 - val_loss: 0.1224 - val_acc: 0.9604\n",
      "Train on 778756 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778756/778756 [==============================] - 2s 2us/step - loss: 0.1215 - acc: 0.9609 - val_loss: 0.1235 - val_acc: 0.9603\n",
      "Train on 778715 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778715/778715 [==============================] - 2s 2us/step - loss: 0.1226 - acc: 0.9607 - val_loss: 0.1250 - val_acc: 0.9600\n",
      "Train on 778886 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778886/778886 [==============================] - 2s 2us/step - loss: 0.1229 - acc: 0.9604 - val_loss: 0.1221 - val_acc: 0.9608\n",
      "Train on 779508 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779508/779508 [==============================] - 2s 2us/step - loss: 0.1225 - acc: 0.9605 - val_loss: 0.1227 - val_acc: 0.9606\n",
      "Train on 778991 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778991/778991 [==============================] - 2s 2us/step - loss: 0.1219 - acc: 0.9607 - val_loss: 0.1223 - val_acc: 0.9609\n",
      "Train on 778828 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778828/778828 [==============================] - 2s 2us/step - loss: 0.1218 - acc: 0.9608 - val_loss: 0.1218 - val_acc: 0.9609\n",
      "Train on 779154 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779154/779154 [==============================] - 2s 2us/step - loss: 0.1225 - acc: 0.9606 - val_loss: 0.1233 - val_acc: 0.9604\n",
      "Train on 777858 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777858/777858 [==============================] - 2s 2us/step - loss: 0.1223 - acc: 0.9608 - val_loss: 0.1224 - val_acc: 0.9607\n",
      "Train on 778788 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778788/778788 [==============================] - 2s 2us/step - loss: 0.1219 - acc: 0.9608 - val_loss: 0.1225 - val_acc: 0.9607\n",
      "Train on 778178 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778178/778178 [==============================] - 2s 2us/step - loss: 0.1222 - acc: 0.9607 - val_loss: 0.1229 - val_acc: 0.9605\n",
      "Train on 778741 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778741/778741 [==============================] - 2s 2us/step - loss: 0.1220 - acc: 0.9607 - val_loss: 0.1219 - val_acc: 0.9608\n",
      "Train on 778934 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778934/778934 [==============================] - 2s 2us/step - loss: 0.1219 - acc: 0.9609 - val_loss: 0.1217 - val_acc: 0.9610\n",
      "Train on 779290 samples, validate on 193733 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "779290/779290 [==============================] - 2s 2us/step - loss: 0.1217 - acc: 0.9608 - val_loss: 0.1233 - val_acc: 0.9603\n",
      "Train on 778829 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778829/778829 [==============================] - 2s 2us/step - loss: 0.1230 - acc: 0.9605 - val_loss: 0.1217 - val_acc: 0.9610\n",
      "Train on 778433 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778433/778433 [==============================] - 2s 2us/step - loss: 0.1221 - acc: 0.9605 - val_loss: 0.1238 - val_acc: 0.9602\n",
      "Train on 778467 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778467/778467 [==============================] - 2s 2us/step - loss: 0.1229 - acc: 0.9604 - val_loss: 0.1241 - val_acc: 0.9601\n",
      "Train on 779067 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779067/779067 [==============================] - 2s 2us/step - loss: 0.1236 - acc: 0.9603 - val_loss: 0.1219 - val_acc: 0.9610\n",
      "Train on 779498 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779498/779498 [==============================] - 2s 2us/step - loss: 0.1222 - acc: 0.9607 - val_loss: 0.1221 - val_acc: 0.9608\n",
      "Train on 778820 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778820/778820 [==============================] - 2s 2us/step - loss: 0.1228 - acc: 0.9605 - val_loss: 0.1216 - val_acc: 0.9608\n",
      "Train on 778984 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778984/778984 [==============================] - 2s 2us/step - loss: 0.1218 - acc: 0.9608 - val_loss: 0.1219 - val_acc: 0.9605\n",
      "Train on 779209 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779209/779209 [==============================] - 2s 2us/step - loss: 0.1225 - acc: 0.9608 - val_loss: 0.1218 - val_acc: 0.9607\n",
      "Train on 779658 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779658/779658 [==============================] - 2s 2us/step - loss: 0.1217 - acc: 0.9609 - val_loss: 0.1223 - val_acc: 0.9606\n",
      "Train on 779679 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779679/779679 [==============================] - 2s 2us/step - loss: 0.1222 - acc: 0.9607 - val_loss: 0.1216 - val_acc: 0.9610\n",
      "Train on 779253 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779253/779253 [==============================] - 2s 2us/step - loss: 0.1224 - acc: 0.9605 - val_loss: 0.1221 - val_acc: 0.9607\n",
      "Train on 779126 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779126/779126 [==============================] - 2s 2us/step - loss: 0.1223 - acc: 0.9607 - val_loss: 0.1229 - val_acc: 0.9607\n",
      "Train on 779584 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779584/779584 [==============================] - 2s 2us/step - loss: 0.1222 - acc: 0.9608 - val_loss: 0.1213 - val_acc: 0.9611\n",
      "Train on 779078 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779078/779078 [==============================] - 2s 2us/step - loss: 0.1213 - acc: 0.9609 - val_loss: 0.1222 - val_acc: 0.9608\n",
      "Train on 779158 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779158/779158 [==============================] - 2s 2us/step - loss: 0.1219 - acc: 0.9606 - val_loss: 0.1216 - val_acc: 0.9610\n",
      "Train on 779105 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779105/779105 [==============================] - 2s 2us/step - loss: 0.1225 - acc: 0.9606 - val_loss: 0.1220 - val_acc: 0.9609\n",
      "Train on 779217 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779217/779217 [==============================] - 2s 2us/step - loss: 0.1219 - acc: 0.9607 - val_loss: 0.1222 - val_acc: 0.9610\n",
      "Train on 779373 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779373/779373 [==============================] - 2s 2us/step - loss: 0.1226 - acc: 0.9607 - val_loss: 0.1232 - val_acc: 0.9603\n",
      "Train on 779227 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779227/779227 [==============================] - 2s 2us/step - loss: 0.1219 - acc: 0.9606 - val_loss: 0.1220 - val_acc: 0.9608\n",
      "Train on 778845 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778845/778845 [==============================] - 2s 2us/step - loss: 0.1217 - acc: 0.9609 - val_loss: 0.1231 - val_acc: 0.9604\n",
      "Train on 778980 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778980/778980 [==============================] - 2s 2us/step - loss: 0.1223 - acc: 0.9608 - val_loss: 0.1213 - val_acc: 0.9610\n",
      "Train on 778547 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778547/778547 [==============================] - 2s 2us/step - loss: 0.1216 - acc: 0.9608 - val_loss: 0.1232 - val_acc: 0.9603\n",
      "Train on 777919 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777919/777919 [==============================] - 2s 2us/step - loss: 0.1224 - acc: 0.9606 - val_loss: 0.1218 - val_acc: 0.9610\n",
      "Train on 778722 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778722/778722 [==============================] - 2s 2us/step - loss: 0.1223 - acc: 0.9605 - val_loss: 0.1216 - val_acc: 0.9608\n",
      "Train on 778699 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778699/778699 [==============================] - 2s 2us/step - loss: 0.1220 - acc: 0.9607 - val_loss: 0.1225 - val_acc: 0.9607\n",
      "Train on 777923 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777923/777923 [==============================] - 2s 2us/step - loss: 0.1223 - acc: 0.9605 - val_loss: 0.1218 - val_acc: 0.9608\n",
      "Train on 778643 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778643/778643 [==============================] - 2s 2us/step - loss: 0.1216 - acc: 0.9609 - val_loss: 0.1222 - val_acc: 0.9603\n",
      "Train on 779331 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779331/779331 [==============================] - 2s 2us/step - loss: 0.1227 - acc: 0.9606 - val_loss: 0.1214 - val_acc: 0.9610\n",
      "Train on 777980 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777980/777980 [==============================] - 2s 2us/step - loss: 0.1215 - acc: 0.9609 - val_loss: 0.1218 - val_acc: 0.9609\n",
      "Train on 778493 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778493/778493 [==============================] - 2s 2us/step - loss: 0.1223 - acc: 0.9606 - val_loss: 0.1219 - val_acc: 0.9610\n",
      "Train on 778184 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778184/778184 [==============================] - 2s 2us/step - loss: 0.1223 - acc: 0.9607 - val_loss: 0.1225 - val_acc: 0.9607\n",
      "Train on 779104 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779104/779104 [==============================] - 2s 2us/step - loss: 0.1225 - acc: 0.9607 - val_loss: 0.1235 - val_acc: 0.9602\n",
      "Train on 779672 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779672/779672 [==============================] - 2s 2us/step - loss: 0.1220 - acc: 0.9609 - val_loss: 0.1216 - val_acc: 0.9609\n",
      "Train on 778912 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778912/778912 [==============================] - 2s 2us/step - loss: 0.1212 - acc: 0.9612 - val_loss: 0.1227 - val_acc: 0.9604\n",
      "Train on 779482 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779482/779482 [==============================] - 2s 2us/step - loss: 0.1218 - acc: 0.9608 - val_loss: 0.1230 - val_acc: 0.9605\n",
      "Train on 779789 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779789/779789 [==============================] - 2s 2us/step - loss: 0.1225 - acc: 0.9607 - val_loss: 0.1225 - val_acc: 0.9608\n",
      "Train on 778956 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778956/778956 [==============================] - 2s 2us/step - loss: 0.1219 - acc: 0.9608 - val_loss: 0.1224 - val_acc: 0.9606\n",
      "Train on 778874 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778874/778874 [==============================] - 2s 2us/step - loss: 0.1219 - acc: 0.9607 - val_loss: 0.1231 - val_acc: 0.9605\n",
      "Train on 779267 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779267/779267 [==============================] - 2s 2us/step - loss: 0.1221 - acc: 0.9608 - val_loss: 0.1218 - val_acc: 0.9608\n",
      "Train on 780029 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "780029/780029 [==============================] - 2s 2us/step - loss: 0.1218 - acc: 0.9608 - val_loss: 0.1224 - val_acc: 0.9607\n",
      "Train on 778657 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778657/778657 [==============================] - 2s 2us/step - loss: 0.1227 - acc: 0.9606 - val_loss: 0.1237 - val_acc: 0.9604\n",
      "Train on 777854 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777854/777854 [==============================] - 2s 2us/step - loss: 0.1217 - acc: 0.9607 - val_loss: 0.1214 - val_acc: 0.9613\n",
      "Train on 777060 samples, validate on 193733 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777060/777060 [==============================] - 2s 2us/step - loss: 0.1218 - acc: 0.9606 - val_loss: 0.1223 - val_acc: 0.9607\n",
      "Train on 779651 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779651/779651 [==============================] - 2s 2us/step - loss: 0.1216 - acc: 0.9608 - val_loss: 0.1224 - val_acc: 0.9608\n",
      "Train on 778354 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778354/778354 [==============================] - 2s 2us/step - loss: 0.1224 - acc: 0.9605 - val_loss: 0.1215 - val_acc: 0.9612\n",
      "Train on 779018 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779018/779018 [==============================] - 2s 2us/step - loss: 0.1214 - acc: 0.9611 - val_loss: 0.1219 - val_acc: 0.9607\n",
      "Train on 777403 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777403/777403 [==============================] - 2s 2us/step - loss: 0.1217 - acc: 0.9607 - val_loss: 0.1218 - val_acc: 0.9610\n",
      "Train on 779645 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779645/779645 [==============================] - 2s 2us/step - loss: 0.1213 - acc: 0.9608 - val_loss: 0.1227 - val_acc: 0.9607\n",
      "Train on 778553 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778553/778553 [==============================] - 2s 2us/step - loss: 0.1221 - acc: 0.9606 - val_loss: 0.1229 - val_acc: 0.9606\n",
      "Train on 779581 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779581/779581 [==============================] - 2s 2us/step - loss: 0.1220 - acc: 0.9606 - val_loss: 0.1221 - val_acc: 0.9606\n",
      "Train on 778837 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778837/778837 [==============================] - 2s 2us/step - loss: 0.1215 - acc: 0.9608 - val_loss: 0.1229 - val_acc: 0.9607\n",
      "Train on 779137 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779137/779137 [==============================] - 2s 2us/step - loss: 0.1219 - acc: 0.9607 - val_loss: 0.1220 - val_acc: 0.9608\n",
      "Train on 779142 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779142/779142 [==============================] - 2s 2us/step - loss: 0.1215 - acc: 0.9607 - val_loss: 0.1222 - val_acc: 0.9609\n",
      "Train on 779068 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779068/779068 [==============================] - 2s 2us/step - loss: 0.1217 - acc: 0.9608 - val_loss: 0.1212 - val_acc: 0.9610\n",
      "Train on 779138 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779138/779138 [==============================] - 2s 2us/step - loss: 0.1216 - acc: 0.9609 - val_loss: 0.1217 - val_acc: 0.9611\n",
      "Train on 778286 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778286/778286 [==============================] - 2s 2us/step - loss: 0.1219 - acc: 0.9606 - val_loss: 0.1373 - val_acc: 0.9552\n",
      "Train on 778627 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778627/778627 [==============================] - 2s 2us/step - loss: 0.1252 - acc: 0.9597 - val_loss: 0.1223 - val_acc: 0.9607\n",
      "Train on 779109 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779109/779109 [==============================] - 2s 2us/step - loss: 0.1225 - acc: 0.9606 - val_loss: 0.1218 - val_acc: 0.9607\n",
      "Train on 778719 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778719/778719 [==============================] - 2s 2us/step - loss: 0.1215 - acc: 0.9609 - val_loss: 0.1226 - val_acc: 0.9608\n",
      "Train on 778588 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778588/778588 [==============================] - 2s 2us/step - loss: 0.1217 - acc: 0.9608 - val_loss: 0.1237 - val_acc: 0.9603\n",
      "Train on 779281 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779281/779281 [==============================] - 2s 2us/step - loss: 0.1221 - acc: 0.9608 - val_loss: 0.1212 - val_acc: 0.9610\n",
      "Train on 779819 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779819/779819 [==============================] - 2s 2us/step - loss: 0.1215 - acc: 0.9608 - val_loss: 0.1220 - val_acc: 0.9607\n",
      "Train on 778587 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778587/778587 [==============================] - 2s 2us/step - loss: 0.1215 - acc: 0.9608 - val_loss: 0.1217 - val_acc: 0.9607\n",
      "Train on 778424 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778424/778424 [==============================] - 2s 2us/step - loss: 0.1214 - acc: 0.9608 - val_loss: 0.1218 - val_acc: 0.9608\n",
      "Train on 778228 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778228/778228 [==============================] - 2s 2us/step - loss: 0.1222 - acc: 0.9607 - val_loss: 0.1216 - val_acc: 0.9612\n",
      "Train on 778795 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778795/778795 [==============================] - 2s 2us/step - loss: 0.1219 - acc: 0.9609 - val_loss: 0.1226 - val_acc: 0.9606\n",
      "Train on 778875 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778875/778875 [==============================] - 2s 2us/step - loss: 0.1218 - acc: 0.9609 - val_loss: 0.1213 - val_acc: 0.9612\n",
      "Train on 779588 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779588/779588 [==============================] - 2s 2us/step - loss: 0.1214 - acc: 0.9610 - val_loss: 0.1219 - val_acc: 0.9611\n",
      "Train on 778274 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778274/778274 [==============================] - 2s 2us/step - loss: 0.1214 - acc: 0.9608 - val_loss: 0.1280 - val_acc: 0.9589\n",
      "Train on 779383 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779383/779383 [==============================] - 2s 2us/step - loss: 0.1261 - acc: 0.9597 - val_loss: 0.1246 - val_acc: 0.9601\n",
      "Train on 778743 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778743/778743 [==============================] - 2s 2us/step - loss: 0.1227 - acc: 0.9606 - val_loss: 0.1226 - val_acc: 0.9607\n",
      "Train on 778430 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778430/778430 [==============================] - 2s 2us/step - loss: 0.1218 - acc: 0.9607 - val_loss: 0.1234 - val_acc: 0.9601\n",
      "Train on 778929 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778929/778929 [==============================] - 2s 2us/step - loss: 0.1218 - acc: 0.9609 - val_loss: 0.1227 - val_acc: 0.9606\n",
      "Train on 778432 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778432/778432 [==============================] - 2s 2us/step - loss: 0.1214 - acc: 0.9610 - val_loss: 0.1233 - val_acc: 0.9603\n",
      "Train on 779385 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779385/779385 [==============================] - 2s 2us/step - loss: 0.1223 - acc: 0.9607 - val_loss: 0.1218 - val_acc: 0.9610\n",
      "Train on 779744 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779744/779744 [==============================] - 2s 2us/step - loss: 0.1215 - acc: 0.9608 - val_loss: 0.1218 - val_acc: 0.9609\n",
      "Train on 778814 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778814/778814 [==============================] - 2s 2us/step - loss: 0.1220 - acc: 0.9607 - val_loss: 0.1221 - val_acc: 0.9607\n",
      "Train on 779028 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779028/779028 [==============================] - 2s 2us/step - loss: 0.1225 - acc: 0.9607 - val_loss: 0.1222 - val_acc: 0.9608\n",
      "Train on 778415 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778415/778415 [==============================] - 2s 2us/step - loss: 0.1214 - acc: 0.9609 - val_loss: 0.1217 - val_acc: 0.9610\n",
      "Train on 778491 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778491/778491 [==============================] - 2s 2us/step - loss: 0.1218 - acc: 0.9607 - val_loss: 0.1220 - val_acc: 0.9608\n",
      "Train on 778513 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778513/778513 [==============================] - 2s 2us/step - loss: 0.1222 - acc: 0.9606 - val_loss: 0.1220 - val_acc: 0.9607\n",
      "Train on 779537 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779537/779537 [==============================] - 2s 2us/step - loss: 0.1219 - acc: 0.9606 - val_loss: 0.1216 - val_acc: 0.9609\n",
      "Train on 779797 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779797/779797 [==============================] - 2s 2us/step - loss: 0.1216 - acc: 0.9609 - val_loss: 0.1212 - val_acc: 0.9610\n",
      "Train on 779394 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779394/779394 [==============================] - 2s 2us/step - loss: 0.1214 - acc: 0.9609 - val_loss: 0.1217 - val_acc: 0.9609\n",
      "Train on 778754 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778754/778754 [==============================] - 2s 2us/step - loss: 0.1220 - acc: 0.9607 - val_loss: 0.1217 - val_acc: 0.9608\n",
      "Train on 780019 samples, validate on 193733 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780019/780019 [==============================] - 2s 2us/step - loss: 0.1216 - acc: 0.9608 - val_loss: 0.1219 - val_acc: 0.9609\n",
      "Train on 778829 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778829/778829 [==============================] - 2s 2us/step - loss: 0.1213 - acc: 0.9608 - val_loss: 0.1214 - val_acc: 0.9613\n",
      "Train on 778763 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778763/778763 [==============================] - 2s 2us/step - loss: 0.1217 - acc: 0.9610 - val_loss: 0.1222 - val_acc: 0.9608\n",
      "Train on 779370 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779370/779370 [==============================] - 2s 2us/step - loss: 0.1218 - acc: 0.9609 - val_loss: 0.1222 - val_acc: 0.9607\n",
      "Train on 778808 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778808/778808 [==============================] - 2s 2us/step - loss: 0.1211 - acc: 0.9612 - val_loss: 0.1218 - val_acc: 0.9608\n",
      "Train on 779324 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779324/779324 [==============================] - 2s 2us/step - loss: 0.1222 - acc: 0.9608 - val_loss: 0.1217 - val_acc: 0.9609\n",
      "Train on 779519 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779519/779519 [==============================] - 2s 2us/step - loss: 0.1218 - acc: 0.9608 - val_loss: 0.1210 - val_acc: 0.9612\n",
      "Train on 778949 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778949/778949 [==============================] - 2s 2us/step - loss: 0.1215 - acc: 0.9609 - val_loss: 0.1218 - val_acc: 0.9608\n",
      "Train on 777487 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777487/777487 [==============================] - 2s 2us/step - loss: 0.1216 - acc: 0.9608 - val_loss: 0.1219 - val_acc: 0.9609\n",
      "Train on 778542 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778542/778542 [==============================] - 2s 2us/step - loss: 0.1218 - acc: 0.9607 - val_loss: 0.1224 - val_acc: 0.9608\n",
      "Train on 778827 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778827/778827 [==============================] - 2s 2us/step - loss: 0.1214 - acc: 0.9610 - val_loss: 0.1214 - val_acc: 0.9610\n",
      "Train on 778939 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778939/778939 [==============================] - 2s 2us/step - loss: 0.1220 - acc: 0.9609 - val_loss: 0.1221 - val_acc: 0.9609\n",
      "Train on 779136 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779136/779136 [==============================] - 2s 2us/step - loss: 0.1220 - acc: 0.9607 - val_loss: 0.1216 - val_acc: 0.9608\n",
      "Train on 779359 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779359/779359 [==============================] - 2s 2us/step - loss: 0.1219 - acc: 0.9608 - val_loss: 0.1224 - val_acc: 0.9606\n",
      "Train on 779569 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779569/779569 [==============================] - 2s 2us/step - loss: 0.1212 - acc: 0.9609 - val_loss: 0.1211 - val_acc: 0.9612\n",
      "Train on 778798 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778798/778798 [==============================] - 2s 2us/step - loss: 0.1217 - acc: 0.9608 - val_loss: 0.1211 - val_acc: 0.9613\n",
      "Train on 779183 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779183/779183 [==============================] - 2s 2us/step - loss: 0.1217 - acc: 0.9607 - val_loss: 0.1218 - val_acc: 0.9610\n",
      "Train on 778907 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778907/778907 [==============================] - 2s 2us/step - loss: 0.1212 - acc: 0.9609 - val_loss: 0.1217 - val_acc: 0.9611\n",
      "Train on 779960 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779960/779960 [==============================] - 2s 2us/step - loss: 0.1212 - acc: 0.9609 - val_loss: 0.1216 - val_acc: 0.9612\n",
      "Train on 778654 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778654/778654 [==============================] - 2s 2us/step - loss: 0.1215 - acc: 0.9611 - val_loss: 0.1213 - val_acc: 0.9611\n",
      "Train on 778681 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778681/778681 [==============================] - 2s 2us/step - loss: 0.1213 - acc: 0.9610 - val_loss: 0.1226 - val_acc: 0.9607\n",
      "Train on 778466 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778466/778466 [==============================] - 2s 2us/step - loss: 0.1218 - acc: 0.9608 - val_loss: 0.1219 - val_acc: 0.9609\n",
      "Train on 778771 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778771/778771 [==============================] - 2s 2us/step - loss: 0.1219 - acc: 0.9610 - val_loss: 0.1216 - val_acc: 0.9611\n",
      "Train on 778476 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778476/778476 [==============================] - 2s 2us/step - loss: 0.1215 - acc: 0.9609 - val_loss: 0.1217 - val_acc: 0.9609\n",
      "Train on 778592 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778592/778592 [==============================] - 2s 2us/step - loss: 0.1213 - acc: 0.9610 - val_loss: 0.1231 - val_acc: 0.9604\n",
      "Train on 778407 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778407/778407 [==============================] - 2s 2us/step - loss: 0.1215 - acc: 0.9609 - val_loss: 0.1245 - val_acc: 0.9601\n",
      "Train on 779502 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779502/779502 [==============================] - 2s 2us/step - loss: 0.1220 - acc: 0.9607 - val_loss: 0.1214 - val_acc: 0.9612\n",
      "Train on 778684 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778684/778684 [==============================] - 2s 2us/step - loss: 0.1209 - acc: 0.9609 - val_loss: 0.1224 - val_acc: 0.9608\n",
      "Train on 778650 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778650/778650 [==============================] - 2s 2us/step - loss: 0.1216 - acc: 0.9609 - val_loss: 0.1214 - val_acc: 0.9611\n",
      "Train on 780090 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "780090/780090 [==============================] - 2s 2us/step - loss: 0.1209 - acc: 0.9611 - val_loss: 0.1217 - val_acc: 0.9608\n",
      "Train on 779873 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779873/779873 [==============================] - 2s 2us/step - loss: 0.1213 - acc: 0.9609 - val_loss: 0.1212 - val_acc: 0.9611\n",
      "Train on 777609 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777609/777609 [==============================] - 2s 2us/step - loss: 0.1215 - acc: 0.9610 - val_loss: 0.1215 - val_acc: 0.9612\n",
      "Train on 778900 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778900/778900 [==============================] - 2s 2us/step - loss: 0.1221 - acc: 0.9608 - val_loss: 0.1222 - val_acc: 0.9606\n",
      "Train on 779027 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779027/779027 [==============================] - 2s 2us/step - loss: 0.1218 - acc: 0.9609 - val_loss: 0.1223 - val_acc: 0.9606\n",
      "Train on 779590 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779590/779590 [==============================] - 2s 2us/step - loss: 0.1214 - acc: 0.9609 - val_loss: 0.1217 - val_acc: 0.9610\n",
      "Train on 779317 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779317/779317 [==============================] - 2s 2us/step - loss: 0.1218 - acc: 0.9608 - val_loss: 0.1223 - val_acc: 0.9608\n",
      "Train on 779857 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779857/779857 [==============================] - 2s 2us/step - loss: 0.1213 - acc: 0.9610 - val_loss: 0.1215 - val_acc: 0.9611\n",
      "Train on 779125 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779125/779125 [==============================] - 2s 2us/step - loss: 0.1216 - acc: 0.9607 - val_loss: 0.1214 - val_acc: 0.9609\n",
      "Train on 778801 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778801/778801 [==============================] - 2s 2us/step - loss: 0.1217 - acc: 0.9608 - val_loss: 0.1215 - val_acc: 0.9609\n",
      "Train on 780059 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "780059/780059 [==============================] - 2s 2us/step - loss: 0.1213 - acc: 0.9611 - val_loss: 0.1220 - val_acc: 0.9609\n",
      "Train on 778462 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778462/778462 [==============================] - 2s 2us/step - loss: 0.1217 - acc: 0.9609 - val_loss: 0.1222 - val_acc: 0.9604\n",
      "Train on 779946 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779946/779946 [==============================] - 2s 2us/step - loss: 0.1218 - acc: 0.9609 - val_loss: 0.1216 - val_acc: 0.9610\n",
      "Train on 778275 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778275/778275 [==============================] - 2s 2us/step - loss: 0.1211 - acc: 0.9610 - val_loss: 0.1247 - val_acc: 0.9599\n",
      "Train on 778852 samples, validate on 193733 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778852/778852 [==============================] - 2s 2us/step - loss: 0.1253 - acc: 0.9597 - val_loss: 0.1222 - val_acc: 0.9609\n",
      "Train on 778954 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778954/778954 [==============================] - 2s 2us/step - loss: 0.1220 - acc: 0.9605 - val_loss: 0.1225 - val_acc: 0.9610\n",
      "Train on 778361 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778361/778361 [==============================] - 2s 2us/step - loss: 0.1212 - acc: 0.9611 - val_loss: 0.1230 - val_acc: 0.9606\n",
      "Train on 779444 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779444/779444 [==============================] - 2s 2us/step - loss: 0.1223 - acc: 0.9606 - val_loss: 0.1227 - val_acc: 0.9608\n",
      "Train on 779768 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779768/779768 [==============================] - 2s 2us/step - loss: 0.1218 - acc: 0.9606 - val_loss: 0.1220 - val_acc: 0.9609\n",
      "Train on 778502 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778502/778502 [==============================] - 2s 2us/step - loss: 0.1214 - acc: 0.9610 - val_loss: 0.1231 - val_acc: 0.9607\n",
      "Train on 778814 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778814/778814 [==============================] - 2s 2us/step - loss: 0.1220 - acc: 0.9607 - val_loss: 0.1222 - val_acc: 0.9607\n",
      "Train on 779001 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779001/779001 [==============================] - 2s 2us/step - loss: 0.1212 - acc: 0.9610 - val_loss: 0.1216 - val_acc: 0.9609\n",
      "Train on 778653 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778653/778653 [==============================] - 2s 2us/step - loss: 0.1218 - acc: 0.9608 - val_loss: 0.1220 - val_acc: 0.9608\n",
      "Train on 779328 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779328/779328 [==============================] - 2s 2us/step - loss: 0.1218 - acc: 0.9608 - val_loss: 0.1216 - val_acc: 0.9611\n",
      "Train on 778898 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778898/778898 [==============================] - 2s 2us/step - loss: 0.1214 - acc: 0.9608 - val_loss: 0.1218 - val_acc: 0.9610\n",
      "Train on 778743 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778743/778743 [==============================] - 2s 2us/step - loss: 0.1218 - acc: 0.9607 - val_loss: 0.1215 - val_acc: 0.9610\n",
      "Train on 779658 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779658/779658 [==============================] - 2s 2us/step - loss: 0.1215 - acc: 0.9610 - val_loss: 0.1212 - val_acc: 0.9611\n",
      "Train on 778450 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778450/778450 [==============================] - 2s 2us/step - loss: 0.1214 - acc: 0.9609 - val_loss: 0.1221 - val_acc: 0.9608\n",
      "Train on 779374 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779374/779374 [==============================] - 2s 2us/step - loss: 0.1218 - acc: 0.9607 - val_loss: 0.1221 - val_acc: 0.9607\n",
      "Train on 778802 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778802/778802 [==============================] - 2s 2us/step - loss: 0.1213 - acc: 0.9609 - val_loss: 0.1226 - val_acc: 0.9605\n",
      "Train on 779412 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779412/779412 [==============================] - 2s 2us/step - loss: 0.1235 - acc: 0.9601 - val_loss: 0.1228 - val_acc: 0.9607\n",
      "Train on 779319 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779319/779319 [==============================] - 2s 2us/step - loss: 0.1216 - acc: 0.9608 - val_loss: 0.1220 - val_acc: 0.9608\n",
      "Train on 779846 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779846/779846 [==============================] - 2s 2us/step - loss: 0.1214 - acc: 0.9609 - val_loss: 0.1217 - val_acc: 0.9610\n",
      "Train on 779206 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779206/779206 [==============================] - 2s 2us/step - loss: 0.1206 - acc: 0.9612 - val_loss: 0.1212 - val_acc: 0.9611\n",
      "Train on 778611 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778611/778611 [==============================] - 2s 2us/step - loss: 0.1214 - acc: 0.9608 - val_loss: 0.1224 - val_acc: 0.9605\n",
      "Train on 779486 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779486/779486 [==============================] - 2s 2us/step - loss: 0.1215 - acc: 0.9610 - val_loss: 0.1211 - val_acc: 0.9611\n",
      "Train on 778484 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778484/778484 [==============================] - 2s 2us/step - loss: 0.1204 - acc: 0.9611 - val_loss: 0.1210 - val_acc: 0.9610\n",
      "Train on 779389 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779389/779389 [==============================] - 2s 2us/step - loss: 0.1216 - acc: 0.9609 - val_loss: 0.1219 - val_acc: 0.9610\n",
      "Train on 777676 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777676/777676 [==============================] - 2s 2us/step - loss: 0.1212 - acc: 0.9609 - val_loss: 0.1218 - val_acc: 0.9610\n",
      "Train on 778568 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778568/778568 [==============================] - 2s 2us/step - loss: 0.1211 - acc: 0.9609 - val_loss: 0.1217 - val_acc: 0.9610\n",
      "Train on 778224 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778224/778224 [==============================] - 2s 2us/step - loss: 0.1213 - acc: 0.9611 - val_loss: 0.1209 - val_acc: 0.9612\n",
      "Train on 778514 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778514/778514 [==============================] - 2s 2us/step - loss: 0.1215 - acc: 0.9609 - val_loss: 0.1227 - val_acc: 0.9606\n",
      "Train on 778726 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778726/778726 [==============================] - 2s 2us/step - loss: 0.1218 - acc: 0.9607 - val_loss: 0.1222 - val_acc: 0.9607\n",
      "Train on 779748 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779748/779748 [==============================] - 2s 2us/step - loss: 0.1210 - acc: 0.9610 - val_loss: 0.1211 - val_acc: 0.9612\n",
      "Train on 778555 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778555/778555 [==============================] - 2s 2us/step - loss: 0.1206 - acc: 0.9610 - val_loss: 0.1238 - val_acc: 0.9603\n",
      "Train on 778261 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778261/778261 [==============================] - 2s 2us/step - loss: 0.1225 - acc: 0.9608 - val_loss: 0.1220 - val_acc: 0.9606\n",
      "Train on 778773 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778773/778773 [==============================] - 2s 2us/step - loss: 0.1211 - acc: 0.9610 - val_loss: 0.1227 - val_acc: 0.9607\n",
      "Train on 778564 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778564/778564 [==============================] - 2s 2us/step - loss: 0.1212 - acc: 0.9610 - val_loss: 0.1230 - val_acc: 0.9604\n",
      "Train on 779150 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779150/779150 [==============================] - 2s 2us/step - loss: 0.1220 - acc: 0.9607 - val_loss: 0.1231 - val_acc: 0.9604\n",
      "Train on 779879 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779879/779879 [==============================] - 2s 2us/step - loss: 0.1214 - acc: 0.9610 - val_loss: 0.1213 - val_acc: 0.9611\n",
      "Train on 778926 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778926/778926 [==============================] - 2s 2us/step - loss: 0.1209 - acc: 0.9611 - val_loss: 0.1221 - val_acc: 0.9608\n",
      "Train on 779674 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779674/779674 [==============================] - 2s 2us/step - loss: 0.1213 - acc: 0.9611 - val_loss: 0.1215 - val_acc: 0.9610\n",
      "Train on 779388 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779388/779388 [==============================] - 2s 2us/step - loss: 0.1216 - acc: 0.9609 - val_loss: 0.1220 - val_acc: 0.9610\n",
      "Train on 779426 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779426/779426 [==============================] - 2s 2us/step - loss: 0.1214 - acc: 0.9610 - val_loss: 0.1225 - val_acc: 0.9606\n",
      "Train on 778601 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778601/778601 [==============================] - 2s 2us/step - loss: 0.1215 - acc: 0.9608 - val_loss: 0.1222 - val_acc: 0.9607\n",
      "Train on 778258 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778258/778258 [==============================] - 2s 2us/step - loss: 0.1210 - acc: 0.9611 - val_loss: 0.1250 - val_acc: 0.9598\n",
      "Train on 779131 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779131/779131 [==============================] - 2s 2us/step - loss: 0.1219 - acc: 0.9609 - val_loss: 0.1219 - val_acc: 0.9608\n",
      "Train on 778562 samples, validate on 193733 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778562/778562 [==============================] - 2s 2us/step - loss: 0.1211 - acc: 0.9610 - val_loss: 0.1213 - val_acc: 0.9612\n",
      "Train on 777985 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777985/777985 [==============================] - 2s 2us/step - loss: 0.1215 - acc: 0.9608 - val_loss: 0.1213 - val_acc: 0.9613\n",
      "Train on 778719 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778719/778719 [==============================] - 2s 2us/step - loss: 0.1208 - acc: 0.9611 - val_loss: 0.1216 - val_acc: 0.9611\n",
      "Train on 779332 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779332/779332 [==============================] - 2s 2us/step - loss: 0.1211 - acc: 0.9611 - val_loss: 0.1221 - val_acc: 0.9608\n",
      "Train on 779148 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779148/779148 [==============================] - 2s 2us/step - loss: 0.1213 - acc: 0.9609 - val_loss: 0.1236 - val_acc: 0.9604\n",
      "Train on 778995 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778995/778995 [==============================] - 2s 2us/step - loss: 0.1209 - acc: 0.9609 - val_loss: 0.1225 - val_acc: 0.9608\n",
      "Train on 779528 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779528/779528 [==============================] - 2s 2us/step - loss: 0.1208 - acc: 0.9612 - val_loss: 0.1215 - val_acc: 0.9609\n",
      "Train on 779006 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779006/779006 [==============================] - 2s 2us/step - loss: 0.1211 - acc: 0.9611 - val_loss: 0.1213 - val_acc: 0.9611\n",
      "Train on 779409 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779409/779409 [==============================] - 2s 2us/step - loss: 0.1216 - acc: 0.9609 - val_loss: 0.1216 - val_acc: 0.9610\n",
      "Train on 779882 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779882/779882 [==============================] - 2s 2us/step - loss: 0.1213 - acc: 0.9609 - val_loss: 0.1222 - val_acc: 0.9608\n",
      "Train on 778524 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778524/778524 [==============================] - 2s 2us/step - loss: 0.1210 - acc: 0.9611 - val_loss: 0.1213 - val_acc: 0.9613\n",
      "Train on 779397 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779397/779397 [==============================] - 2s 2us/step - loss: 0.1208 - acc: 0.9612 - val_loss: 0.1212 - val_acc: 0.9612\n",
      "Train on 779179 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779179/779179 [==============================] - 2s 2us/step - loss: 0.1211 - acc: 0.9611 - val_loss: 0.1223 - val_acc: 0.9609\n",
      "Train on 778664 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778664/778664 [==============================] - 2s 2us/step - loss: 0.1212 - acc: 0.9609 - val_loss: 0.1213 - val_acc: 0.9614\n",
      "Train on 778996 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778996/778996 [==============================] - 2s 2us/step - loss: 0.1211 - acc: 0.9612 - val_loss: 0.1214 - val_acc: 0.9611\n",
      "Train on 778722 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778722/778722 [==============================] - 2s 2us/step - loss: 0.1213 - acc: 0.9610 - val_loss: 0.1215 - val_acc: 0.9608\n",
      "Train on 778228 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778228/778228 [==============================] - 2s 2us/step - loss: 0.1209 - acc: 0.9611 - val_loss: 0.1213 - val_acc: 0.9610\n",
      "Train on 778581 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778581/778581 [==============================] - 2s 2us/step - loss: 0.1205 - acc: 0.9611 - val_loss: 0.1220 - val_acc: 0.9609\n",
      "Train on 778656 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778656/778656 [==============================] - 2s 2us/step - loss: 0.1217 - acc: 0.9608 - val_loss: 0.1216 - val_acc: 0.9611\n",
      "Train on 778812 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778812/778812 [==============================] - 2s 2us/step - loss: 0.1209 - acc: 0.9610 - val_loss: 0.1227 - val_acc: 0.9608\n",
      "Train on 779125 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779125/779125 [==============================] - 2s 2us/step - loss: 0.1214 - acc: 0.9609 - val_loss: 0.1224 - val_acc: 0.9609\n",
      "Train on 778439 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778439/778439 [==============================] - 2s 2us/step - loss: 0.1204 - acc: 0.9611 - val_loss: 0.1227 - val_acc: 0.9605\n",
      "Train on 779432 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779432/779432 [==============================] - 2s 2us/step - loss: 0.1213 - acc: 0.9610 - val_loss: 0.1223 - val_acc: 0.9608\n",
      "Train on 779491 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779491/779491 [==============================] - 2s 2us/step - loss: 0.1213 - acc: 0.9611 - val_loss: 0.1214 - val_acc: 0.9609\n",
      "Train on 778575 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778575/778575 [==============================] - 2s 2us/step - loss: 0.1213 - acc: 0.9610 - val_loss: 0.1222 - val_acc: 0.9608\n",
      "Train on 779278 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779278/779278 [==============================] - 2s 2us/step - loss: 0.1207 - acc: 0.9610 - val_loss: 0.1210 - val_acc: 0.9611\n",
      "Train on 778016 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778016/778016 [==============================] - 2s 2us/step - loss: 0.1211 - acc: 0.9610 - val_loss: 0.1217 - val_acc: 0.9610\n",
      "Train on 779403 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779403/779403 [==============================] - 2s 2us/step - loss: 0.1219 - acc: 0.9610 - val_loss: 0.1228 - val_acc: 0.9609\n",
      "Train on 778557 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778557/778557 [==============================] - 2s 2us/step - loss: 0.1218 - acc: 0.9608 - val_loss: 0.1217 - val_acc: 0.9610\n",
      "Train on 778689 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778689/778689 [==============================] - 2s 2us/step - loss: 0.1212 - acc: 0.9610 - val_loss: 0.1210 - val_acc: 0.9613\n",
      "Train on 779046 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779046/779046 [==============================] - 2s 2us/step - loss: 0.1209 - acc: 0.9609 - val_loss: 0.1215 - val_acc: 0.9612\n",
      "Train on 779041 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779041/779041 [==============================] - 2s 2us/step - loss: 0.1209 - acc: 0.9614 - val_loss: 0.1214 - val_acc: 0.9611\n",
      "Train on 779132 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779132/779132 [==============================] - 2s 2us/step - loss: 0.1211 - acc: 0.9611 - val_loss: 0.1224 - val_acc: 0.9610\n",
      "Train on 778848 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778848/778848 [==============================] - 2s 2us/step - loss: 0.1215 - acc: 0.9608 - val_loss: 0.1218 - val_acc: 0.9610\n",
      "Train on 779143 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779143/779143 [==============================] - 2s 2us/step - loss: 0.1217 - acc: 0.9609 - val_loss: 0.1212 - val_acc: 0.9613\n",
      "Train on 779834 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779834/779834 [==============================] - 2s 2us/step - loss: 0.1202 - acc: 0.9615 - val_loss: 0.1214 - val_acc: 0.9611\n",
      "Train on 778844 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778844/778844 [==============================] - 2s 2us/step - loss: 0.1208 - acc: 0.9611 - val_loss: 0.1223 - val_acc: 0.9609\n",
      "Train on 778765 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778765/778765 [==============================] - 2s 2us/step - loss: 0.1212 - acc: 0.9610 - val_loss: 0.1223 - val_acc: 0.9609\n",
      "Train on 779365 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779365/779365 [==============================] - 2s 2us/step - loss: 0.1210 - acc: 0.9612 - val_loss: 0.1215 - val_acc: 0.9611\n",
      "Train on 779362 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779362/779362 [==============================] - 2s 2us/step - loss: 0.1208 - acc: 0.9610 - val_loss: 0.1216 - val_acc: 0.9609\n",
      "Train on 778325 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778325/778325 [==============================] - 2s 2us/step - loss: 0.1217 - acc: 0.9609 - val_loss: 0.1264 - val_acc: 0.9591\n",
      "Train on 778679 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778679/778679 [==============================] - 2s 2us/step - loss: 0.1249 - acc: 0.9598 - val_loss: 0.1227 - val_acc: 0.9607\n",
      "Train on 778169 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778169/778169 [==============================] - 2s 2us/step - loss: 0.1224 - acc: 0.9607 - val_loss: 0.1211 - val_acc: 0.9612\n",
      "Train on 778216 samples, validate on 193733 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778216/778216 [==============================] - 2s 2us/step - loss: 0.1213 - acc: 0.9610 - val_loss: 0.1213 - val_acc: 0.9612\n",
      "Train on 778815 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778815/778815 [==============================] - 2s 2us/step - loss: 0.1211 - acc: 0.9610 - val_loss: 0.1210 - val_acc: 0.9613\n",
      "Train on 779890 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779890/779890 [==============================] - 2s 2us/step - loss: 0.1209 - acc: 0.9611 - val_loss: 0.1214 - val_acc: 0.9611\n",
      "Train on 779141 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779141/779141 [==============================] - 2s 2us/step - loss: 0.1212 - acc: 0.9610 - val_loss: 0.1214 - val_acc: 0.9608\n",
      "Train on 779009 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779009/779009 [==============================] - 2s 2us/step - loss: 0.1208 - acc: 0.9610 - val_loss: 0.1209 - val_acc: 0.9612\n",
      "Train on 779063 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "779063/779063 [==============================] - 2s 2us/step - loss: 0.1210 - acc: 0.9610 - val_loss: 0.1224 - val_acc: 0.9608\n",
      "Train on 778693 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778693/778693 [==============================] - 2s 2us/step - loss: 0.1210 - acc: 0.9612 - val_loss: 0.1213 - val_acc: 0.9612\n",
      "Train on 778890 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778890/778890 [==============================] - 2s 2us/step - loss: 0.1215 - acc: 0.9608 - val_loss: 0.1217 - val_acc: 0.9610\n",
      "Train on 778277 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778277/778277 [==============================] - 2s 2us/step - loss: 0.1213 - acc: 0.9609 - val_loss: 0.1280 - val_acc: 0.9590\n",
      "Train on 777881 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "777881/777881 [==============================] - 2s 2us/step - loss: 0.1233 - acc: 0.9600 - val_loss: 0.1217 - val_acc: 0.9608\n",
      "Train on 778672 samples, validate on 193733 samples\n",
      "Epoch 1/1\n",
      "778672/778672 [==============================] - 2s 2us/step - loss: 0.1213 - acc: 0.9609 - val_loss: 0.1213 - val_acc: 0.9611\n"
     ]
    }
   ],
   "source": [
    "balancer = extract_balanced_indices(y_train, f=1.0)\n",
    "\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "for _, idx in zip(ProgressBar(range(1000)), balancer):\n",
    "    idx = next(balancer)\n",
    "    perm = numpy.random.permutation(idx.sum())\n",
    "    h = model.fit(\n",
    "        X_train[idx][perm], y_train[idx][perm],\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=1, batch_size=4 * 2048, verbose=1\n",
    "    )\n",
    "    if 'history' in globals():\n",
    "        for k in history.history:\n",
    "            history.history[k].extend(h.history[k])\n",
    "    else:\n",
    "        history = h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 500)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k, v in history.history.items():\n",
    "    pyplot.plot(v, label=k, linewidth=4)\n",
    "    \n",
    "pyplot.legend()\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.xlabel('accuracy or loss')\n",
    "pyplot.xlim(0, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193733/193733 [==============================] - 0s 1us/step\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     GALAXY       0.93      0.97      0.95     64665\n",
      "        QSO       0.97      0.94      0.95     64264\n",
      "       STAR       0.98      0.97      0.98     64804\n",
      "\n",
      "avg / total       0.96      0.96      0.96    193733\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test, verbose=1, batch_size=4 * 2048)\n",
    "\n",
    "print(classification_report(y_test, y_pred.argmax(1), target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred.argmax(1)), labels, title='')\n",
    "pyplot.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
